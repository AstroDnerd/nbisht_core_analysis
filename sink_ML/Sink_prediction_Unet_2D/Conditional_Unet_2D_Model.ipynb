{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET MODEL\n",
    "> Created May. 2025 <br>\n",
    "> Nikhil Bisht<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cpu \n"
     ]
    }
   ],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "import h5py \n",
    "import argparse\n",
    "# standard module for tabular data\n",
    "import json\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "# standard statistical module\n",
    "import scipy.stats as st\n",
    "from scipy import linalg\n",
    "from scipy.stats import ks_2samp\n",
    "import skimage as ski\n",
    "from skimage.metrics import structural_similarity as ski_ssim, normalized_mutual_information as ski_nmi\n",
    "\n",
    "# standard module for high-quality plots\n",
    "from PIL import Image\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "mp.rcParams.update(mp.rcParamsDefault)\n",
    "%matplotlib inline\n",
    "\n",
    "# to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import tables\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "from modules import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "seed = 128\n",
    "rnd  = np.random.RandomState(seed)\n",
    "\n",
    "DATAFILE  = '/home/x-nbisht1/scratch/projects/128/B2/datasets/nb101_ML_dataset_AllData_AutoEnc.h5'\n",
    "IMAGEINPUT = '/home/x-nbisht1/scratch/projects/128/B2/datasets/Unet/Images_Input_2D/'\n",
    "IMAGEOUTPUT = '/home/x-nbisht1/scratch/projects/128/B2/datasets/Unet/Images_Output_2D/'\n",
    "CORESET  = '/home/x-nbisht1/scratch/projects/128/B2/datasets/nb101_all_frames.h5'\n",
    "DENSITYCUBES = '/home/x-nbisht1/scratch/projects/128/B2/datasets/nb101_TimeseriesCubes_Density.npy'\n",
    "MODELFILE = 'nnmodel.dict'\n",
    "\n",
    "IMAGESIZE = 128\n",
    "FRAMES = np.arange(0,90, 1)\n",
    "FRAME_DIFF = 30\n",
    "TEST_PERCENTAGE = 0.01\n",
    "\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f'Available device: {str(DEVICE):4s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transform(np_arr):\n",
    "    return np.log10(np_arr)\n",
    "\n",
    "def img_inverse_transform(np_arr):\n",
    "    return np.power(10,np_arr)\n",
    "\n",
    "def plot_test_img(input_arr, pred_output_arr, act_output_arr, label, test_loss, save_filename='xy_data.png', dont_show = False):\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ax  = fig.add_subplot(1, 3, 1)\n",
    "    c = ax.pcolormesh(input_arr.T)\n",
    "    fig.colorbar(c, ax=ax)\n",
    "    ax.set_title('Input: '+str(label[0])+'_'+str(label[1])+'_'+str(label[2])+'\\n Input Loss: '+'{:0.5f}'.format(test_loss[0]))\n",
    "    ax.grid('both')\n",
    "\n",
    "    ax2  = fig.add_subplot(1, 3, 2)\n",
    "    c = ax2.pcolormesh(pred_output_arr.T)\n",
    "    fig.colorbar(c, ax=ax2)\n",
    "    ax2.set_title('Predicted Output '+str(label[0])+'_'+str(label[1])+'_'+str(label[2]))\n",
    "    ax2.grid('both')\n",
    "\n",
    "    ax3  = fig.add_subplot(1, 3, 3)\n",
    "    c = ax3.pcolormesh(act_output_arr.T)\n",
    "    fig.colorbar(c, ax=ax3)\n",
    "    ax3.set_title('Actual Output '+str(label[0])+'_'+str(label[1])+'_'+str(label[2])+'\\n Test Loss: '+'{:0.5f}'.format(test_loss[1]))\n",
    "    ax3.grid('both')\n",
    "\n",
    "\n",
    "    if save_filename:\n",
    "        plt.savefig(save_filename)\n",
    "    \n",
    "    if dont_show==False:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def delete_folder_contents(folder):\n",
    "    import shutil\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def get_images(input_dir):\n",
    "    output_dic = {}\n",
    "    for filename in os.listdir(input_dir):\n",
    "        infile = open(os.path.join(input_dir, filename), 'r')\n",
    "        i_file = json.load(infile)\n",
    "        num = filename.split('_')[1]\n",
    "        img_dic = i_file['img']\n",
    "        label = i_file['label']\n",
    "        output_dic[num] = {'img': img_dic, 'label': label}\n",
    "        infile.close()\n",
    "    return output_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_dic = get_images(IMAGEINPUT)\n",
    "output_image_dic = get_images(IMAGEOUTPUT)\n",
    "input_image_arr = []\n",
    "output_image_arr = []\n",
    "label_arr = []\n",
    "for key in input_image_dic.keys():\n",
    "    input_image_arr.append(torch.tensor(input_image_dic[key]['img']))\n",
    "    output_image_arr.append(torch.tensor(output_image_dic[key]['img']))\n",
    "    label_arr.append(input_image_dic[key]['label'])\n",
    "input_image_train, input_image_test, output_image_train, output_image_test, label_train, label_test = train_test_split(input_image_arr, output_image_arr, label_arr, \n",
    "                                                                                                                       shuffle = False, test_size=TEST_PERCENTAGE, random_state=seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, base_filters=32):\n",
    "        super().__init__()\n",
    "        # Encoder path\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, base_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_filters, base_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(base_filters, base_filters*2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_filters*2, base_filters*2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # (You can add more encoder levels here…)\n",
    "\n",
    "        # Decoder path\n",
    "        self.upconv2 = nn.ConvTranspose2d(base_filters*2, base_filters, kernel_size=2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(base_filters*2, base_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(base_filters, base_filters, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        # (Add more decoder levels to mirror the encoder…)\n",
    "\n",
    "        # Final 1×1 conv to map to desired output channels\n",
    "        self.outconv = nn.Conv2d(base_filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)                          # [B, F, H, W]\n",
    "        e2 = self.enc2(self.pool(e1))              # [B, 2F, H/2, W/2]\n",
    "        # (encode deeper levels…)\n",
    "\n",
    "        # Decoder\n",
    "        d2 = self.upconv2(e2)                      # [B, F, H, W]\n",
    "        d2 = torch.cat([d2, e1], dim=1)            # skip connection\n",
    "        d2 = self.dec2(d2)                         # [B, F, H, W]\n",
    "        # (decode through further levels…)\n",
    "\n",
    "        return self.outconv(d2)                    # [B, out_channels, H, W]\n",
    "\n",
    "\n",
    "def train_unet(input_arr, output_arr, labels, args):\n",
    "    X = torch.stack(input_arr, dim=0).float().unsqueeze(1)  # [N,1,128,128]\n",
    "    Y = torch.stack(output_arr, dim=0).float().unsqueeze(1) # [N,1,128,128]\n",
    "\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader  = DataLoader(dataset,\n",
    "                         batch_size=args.batch_size,\n",
    "                         shuffle=True,\n",
    "                         num_workers=2,    # adjust based on your CPU\n",
    "                         pin_memory=True)  # if using GPU\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = UNet2D(in_channels=1, out_channels=1).to(DEVICE)\n",
    "    # For trainable weights\n",
    "    loss_w = torch.nn.Parameter(torch.ones(4, device=DEVICE), requires_grad=True)\n",
    "    optimizer = optim.Adam(list(model.parameters()) + [loss_w], lr=args.lr)\n",
    "    writer = SummaryWriter(log_dir=f\"./logs/{args.run_name}\")\n",
    "    mass_scale = 0.1   # give mass only 10% initial influence\n",
    "\n",
    "    if args.loss_type == 'static':\n",
    "        #Precompute initial-loss weights\n",
    "        with torch.no_grad():\n",
    "            x0 = X[0:1].to(DEVICE)\n",
    "            y0 = Y[0:1].to(DEVICE)\n",
    "            p0 = model(x0)\n",
    "            #L1\n",
    "            L1_0   = F.l1_loss(p0, y0).item()\n",
    "            # MSE\n",
    "            mse = F.mse_loss(p0, y0)\n",
    "            #SSIM (1 - SSIM)\n",
    "            ssim_func = StructuralSimilarityIndexMeasure()\n",
    "            SSIM_0 = 1 - ssim_func(p0, y0)\n",
    "            #Mass (invert log10 before summation)\n",
    "            mass_true = torch.pow(10, y0).sum().item()\n",
    "            mass_pred = torch.pow(10, p0).sum().item()\n",
    "            MASS_0 = abs(mass_pred - mass_true) / (mass_true+ 1e-8)\n",
    "            init_w = torch.tensor([1/L1_0, 1/mse, 1/SSIM_0, mass_scale/MASS_0],device=DEVICE)\n",
    "            static_w = init_w / init_w.sum()\n",
    "\n",
    "    # === Training loop ===\n",
    "    loss_history = []\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        total_epoch_loss = 0.0\n",
    "        sum_l1, sum_mse, sum_ssim, sum_mass = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            #Computing individual losses\n",
    "            #L1 loss\n",
    "            l1 = F.l1_loss(pred, y)\n",
    "            # MSE\n",
    "            mse = F.mse_loss(pred, y)\n",
    "            #SSIM loss = 1 − SSIM\n",
    "            ssim_func = StructuralSimilarityIndexMeasure()\n",
    "            ssim_l = 1 - ssim_func(pred, y)\n",
    "            #Mass loss (invert log10)\n",
    "            mass_t = torch.pow(10, y).sum()\n",
    "            mass_p = torch.pow(10, pred).sum()\n",
    "            mass_error = torch.abs(mass_p - mass_t) / (mass_t + 1e-8)\n",
    "            mass_l = torch.log1p(mass_error)  # log1p to avoid large values\n",
    "            #Stacking losses\n",
    "            losses = torch.stack([l1, mse, ssim_l, mass_l])\n",
    "            if args.loss_type == 'static':\n",
    "                total_loss = (static_w * losses).sum()\n",
    "            else:\n",
    "                w = torch.softmax(loss_w, dim=0)\n",
    "                total_loss = (w * losses).sum()\n",
    "\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # optional\n",
    "            optimizer.step()\n",
    "            # accumulate\n",
    "            batch_size = x.size(0)\n",
    "            total_epoch_loss += total_loss.item() * batch_size\n",
    "            sum_l1     += l1.item()      * batch_size\n",
    "            sum_mse    += mse.item()     * batch_size\n",
    "            sum_ssim   += ssim_l.item()  * batch_size\n",
    "            sum_mass   += mass_l.item()  * batch_size\n",
    "\n",
    "        # compute per-sample averages\n",
    "        N = len(dataset)\n",
    "        avg_total = total_epoch_loss / N\n",
    "        avg_l1    = sum_l1     / N\n",
    "        avg_mse   = sum_mse    / N\n",
    "        avg_ssim  = sum_ssim   / N\n",
    "        avg_mass  = sum_mass   / N\n",
    "        # log to console\n",
    "        print(f\"Epoch {epoch+1}: \"\n",
    "              f\"Total={avg_total:.4f} | \"\n",
    "              f\"L1={avg_l1:.4f} MSE={avg_mse:.4f} \"\n",
    "              f\"SSIM={avg_ssim:.4f} Mass={avg_mass:.4f}\")\n",
    "\n",
    "        # log to TensorBoard\n",
    "        writer.add_scalar(\"Loss/Total\",    avg_total, epoch)\n",
    "        writer.add_scalar(\"Loss/L1\",       avg_l1,    epoch)\n",
    "        writer.add_scalar(\"Loss/MSE\",     avg_mse,   epoch)\n",
    "        writer.add_scalar(\"Loss/SSIM\",     avg_ssim,  epoch)\n",
    "        writer.add_scalar(\"Loss/Mass\",     avg_mass,  epoch)\n",
    "\n",
    "        if args.loss_type!='static':\n",
    "            # log the learned weights (after softmax)\n",
    "            curr_w = torch.softmax(loss_w, dim=0).detach().cpu().tolist()\n",
    "            for i, name in enumerate([\"L1\",\"MSE\",\"SSIM\",\"Mass\"]):\n",
    "                writer.add_scalar(f\"Weights/{name}\", curr_w[i], epoch)\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    # === Save & plot ===\n",
    "    torch.save(model.state_dict(), MODELFILE)\n",
    "    if args.loss_type != 'static':\n",
    "        torch.save(loss_w.detach().cpu(), \"./plots/loss_weights.pt\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(loss_history, marker='o')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Avg Weighted Loss\")\n",
    "    plt.title(f\"{args.run_name} Training Loss\")\n",
    "    plt.savefig(f\"./plots/{args.run_name}_training_loss.png\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch training\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "args.batch_size = 1\n",
    "args.image_size = IMAGESIZE\n",
    "args.device = DEVICE\n",
    "args.run_name = \"Unet_2D\"\n",
    "args.epochs = 30\n",
    "args.lr = 3e-4\n",
    "args.loss_type = 'static' # 'static' or 'dynamic'\n",
    "\n",
    "\n",
    "#train_unet(input_image_train, output_image_train, label_train, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation for different metrics\n",
    "[scikit-image documentation](https://scikit-image.org/docs/0.25.x/api/skimage.metrics.html#module-skimage.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing completed and output images plotted.\n"
     ]
    }
   ],
   "source": [
    "def plot_comparison(input_arr, pred_output_arr, act_output_arr, label, save_filename='xy_data.png', dont_show = False):\n",
    "    input_str = 'INPUT IMAGE:\\n'\n",
    "    pred_str = 'PREDICTED IMAGE:\\n'\n",
    "    act_str = 'ACTUAL IMAGE:\\n'\n",
    "    # Calculate metrics\n",
    "    input_MSE = ski.metrics.mean_squared_error(act_output_arr, input_arr)\n",
    "    input_str+= 'MSE: '+'{:0.5f}'.format(input_MSE)+'\\n'\n",
    "    pred_MSE = ski.metrics.mean_squared_error(act_output_arr, pred_output_arr)\n",
    "    pred_str+= 'MSE: '+'{:0.5f}'.format(pred_MSE)+'\\n'\n",
    "    actual_MSE = ski.metrics.mean_squared_error(act_output_arr, act_output_arr)\n",
    "    act_str+= 'MSE: '+'{:0.5f}'.format(actual_MSE)+'\\n'\n",
    "\n",
    "    input_NMI = ski.metrics.normalized_mutual_information(act_output_arr, input_arr, bins=100)\n",
    "    input_str+= 'NMI: '+'{:0.5f}'.format(input_NMI)+'\\n'\n",
    "    pred_NMI = ski.metrics.normalized_mutual_information(act_output_arr, pred_output_arr, bins=100)\n",
    "    pred_str+= 'NMI: '+'{:0.5f}'.format(pred_NMI)+'\\n'\n",
    "    actual_NMI = ski.metrics.normalized_mutual_information(act_output_arr, act_output_arr, bins=100)\n",
    "    act_str+= 'NMI: '+'{:0.5f}'.format(actual_NMI)+'\\n'\n",
    "\n",
    "    inversed_input_arr = img_inverse_transform(input_arr)\n",
    "    inversed_pred_output_arr = img_inverse_transform(pred_output_arr)\n",
    "    inversed_act_output_arr = img_inverse_transform(act_output_arr)\n",
    "    input_PSNR = ski.metrics.peak_signal_noise_ratio(inversed_act_output_arr, inversed_input_arr, data_range=np.max(inversed_input_arr) - np.min(inversed_input_arr))\n",
    "    input_str+= 'PSNR: '+'{:0.5f}'.format(input_PSNR)+'\\n'\n",
    "    pred_PSNR = ski.metrics.peak_signal_noise_ratio(inversed_act_output_arr, inversed_pred_output_arr, data_range=np.max(inversed_pred_output_arr) - np.min(inversed_pred_output_arr))\n",
    "    pred_str+= 'PSNR: '+'{:0.5f}'.format(pred_PSNR)+'\\n'\n",
    "    actual_PSNR = ski.metrics.peak_signal_noise_ratio(inversed_act_output_arr, inversed_act_output_arr, data_range=np.max(inversed_act_output_arr) - np.min(inversed_act_output_arr))\n",
    "    act_str+= 'PSNR: '+'{:0.5f}'.format(actual_PSNR)+'\\n'\n",
    "\n",
    "    input_SSI = ski.metrics.structural_similarity(act_output_arr, input_arr, gradient=False, data_range=np.max(input_arr) - np.min(input_arr), channel_axis=None)\n",
    "    input_str+= 'SSI: '+'{:0.5f}'.format(input_SSI)+'\\n'\n",
    "    pred_SSI = ski.metrics.structural_similarity(act_output_arr, pred_output_arr, gradient=False, data_range=np.max(pred_output_arr) - np.min(pred_output_arr), channel_axis=None)\n",
    "    pred_str+= 'SSI: '+'{:0.5f}'.format(pred_SSI)+'\\n'\n",
    "    actual_SSI = ski.metrics.structural_similarity(act_output_arr, act_output_arr, gradient=False, data_range=np.max(act_output_arr) - np.min(act_output_arr), channel_axis=None)\n",
    "    act_str+= 'SSI: '+'{:0.5f}'.format(actual_SSI)+'\\n'\n",
    "\n",
    "    input_total_density = np.sum(inversed_input_arr)\n",
    "    input_str+= 'Total Density: '+'{:0.5f}'.format(input_total_density)+'\\n'\n",
    "    pred_total_density = np.sum(inversed_pred_output_arr)\n",
    "    pred_str+= 'Total Density: '+'{:0.5f}'.format(pred_total_density)+'\\n'\n",
    "    act_total_density = np.sum(inversed_act_output_arr)\n",
    "    act_str+= 'Total Density: '+'{:0.5f}'.format(act_total_density)+'\\n'\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    ax  = fig.add_subplot(1, 3, 1)\n",
    "    c = ax.pcolormesh(input_arr.T)\n",
    "    fig.colorbar(c, ax=ax)\n",
    "    ax.set_title('Input: '+str(label[0])+'_'+str(label[1])+'_'+str(label[2]))\n",
    "    ax.grid('both')\n",
    "    ax.text(0.15, -0.25, input_str, fontsize=10, transform=plt.gcf().transFigure, bbox=dict(boxstyle=\"round\", edgecolor='black', facecolor='white'))\n",
    "\n",
    "    ax2  = fig.add_subplot(1, 3, 2)\n",
    "    c = ax2.pcolormesh(pred_output_arr.T)\n",
    "    fig.colorbar(c, ax=ax2)\n",
    "    ax2.set_title('Predicted Output '+str(label[0])+'_'+str(label[1])+'_'+str(label[2]))\n",
    "    ax2.grid('both')\n",
    "    ax2.text(0.4, -0.25, pred_str, fontsize=10, transform=plt.gcf().transFigure, bbox=dict(boxstyle=\"round\", edgecolor='black', facecolor='white'))\n",
    "\n",
    "    ax3  = fig.add_subplot(1, 3, 3)\n",
    "    c = ax3.pcolormesh(act_output_arr.T)\n",
    "    fig.colorbar(c, ax=ax3)\n",
    "    ax3.set_title('Actual Output '+str(label[0])+'_'+str(label[1])+'_'+str(label[2]))\n",
    "    ax3.grid('both')\n",
    "    ax3.text(0.7, -0.25, act_str, fontsize=10, transform=plt.gcf().transFigure, bbox=dict(boxstyle=\"round\", edgecolor='black', facecolor='white'))\n",
    "\n",
    "\n",
    "    if save_filename:\n",
    "        plt.savefig(save_filename, bbox_inches='tight')\n",
    "    \n",
    "    if dont_show==False:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def compare_output(input_arr, output_arr, labels, args):\n",
    "    # Load the trained model\n",
    "    model = UNet2D(in_channels=1, out_channels=1).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(MODELFILE))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(input_arr)):\n",
    "            inputs = input_arr[i].unsqueeze(0).unsqueeze(0)\n",
    "            targets = output_arr[i].unsqueeze(0).unsqueeze(0)\n",
    "            label = labels[i]\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            # Save the output images\n",
    "            output_image = outputs.cpu().numpy()\n",
    "            plot_comparison(inputs[0][0].numpy(), output_image[0][0], targets[0][0].numpy(), label, save_filename='./2D_test_plots/img'+\"_\".join(str(x) for x in label)+'.png', dont_show = True)\n",
    "    print(\"Testing completed and output images plotted.\")\n",
    "\n",
    "compare_output(input_image_test, output_image_test, label_test, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "* Add info about what frame or time is being looked at\n",
    "* look at the Unet structure and draw it out\n",
    "* Also, is the MSE actually good? what does it represent in terms of value? if initial is set as final, what is the MSE then? as comparison\n",
    "* add NMI, PSNR, SSI and total density to loss [here's a link](https://medium.com/@baicenxiao/strategies-for-balancing-multiple-loss-functions-in-deep-learning-e1a641e0bcc0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbisht_06032025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
