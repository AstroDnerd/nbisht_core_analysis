{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepNN for Sink Particles\n",
    "> Created Oct. 2024 <br>\n",
    "> Nikhil Bisht<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "\n",
    "# standard statistical module\n",
    "import scipy.stats as st\n",
    "\n",
    "# standard module for high-quality plots\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "mp.rcParams.update(mp.rcParamsDefault)\n",
    "%matplotlib inline\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "seed = 128\n",
    "rnd  = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cpu \n",
      "8 8\n"
     ]
    }
   ],
   "source": [
    "DATAFILE  = '/data/cb1/nbisht/anvil_scratch/projects/128/B2/datasets/final_88/nb101_ML_dataset.csv'\n",
    "MODELFILE = 'nnmodel.dict'\n",
    "\n",
    "NTRAIN = 1600000\n",
    "NVALID =  100000\n",
    "NTEST  =  300000 #roughly\n",
    "\n",
    "TARGET = ['O_Clump_X', 'O_Clump_Y',\t'O_Clump_Z', 'O_Clump_Vx', 'O_Clump_Vy', 'O_Clump_Vz', 'O_Clump_density','O_t_end']\n",
    "FEATURES = ['X', 'Y', 'Z', 'Density', 'Vx', 'Vy', 'Vz', 't_hard']\n",
    "\n",
    "n_input = len(FEATURES)\n",
    "n_output = len(TARGET)\n",
    "\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f'Available device: {str(DEVICE):4s}')\n",
    "print(n_input, n_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2097152\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clump_id</th>\n",
       "      <th>Particle_id</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Density</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "      <th>t_hard</th>\n",
       "      <th>O_Clump_X</th>\n",
       "      <th>O_Clump_Y</th>\n",
       "      <th>O_Clump_Z</th>\n",
       "      <th>O_Clump_Vx</th>\n",
       "      <th>O_Clump_Vy</th>\n",
       "      <th>O_Clump_Vz</th>\n",
       "      <th>O_Clump_density</th>\n",
       "      <th>O_t_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325643</td>\n",
       "      <td>-1</td>\n",
       "      <td>765198.0</td>\n",
       "      <td>0.998508</td>\n",
       "      <td>0.953404</td>\n",
       "      <td>0.897660</td>\n",
       "      <td>0.279144</td>\n",
       "      <td>-6.064194</td>\n",
       "      <td>0.293609</td>\n",
       "      <td>-1.328493</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.932550</td>\n",
       "      <td>0.946430</td>\n",
       "      <td>0.891439</td>\n",
       "      <td>-7.100963</td>\n",
       "      <td>-0.826690</td>\n",
       "      <td>-0.527203</td>\n",
       "      <td>0.278950</td>\n",
       "      <td>0.66003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492523</td>\n",
       "      <td>-1</td>\n",
       "      <td>22465.0</td>\n",
       "      <td>0.963346</td>\n",
       "      <td>0.239255</td>\n",
       "      <td>0.921146</td>\n",
       "      <td>1.553199</td>\n",
       "      <td>-4.098066</td>\n",
       "      <td>3.169495</td>\n",
       "      <td>-1.430379</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.935869</td>\n",
       "      <td>0.267055</td>\n",
       "      <td>0.914330</td>\n",
       "      <td>-1.835060</td>\n",
       "      <td>2.208904</td>\n",
       "      <td>0.159224</td>\n",
       "      <td>2.434835</td>\n",
       "      <td>0.66003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1411925</td>\n",
       "      <td>-1</td>\n",
       "      <td>1380389.0</td>\n",
       "      <td>0.778422</td>\n",
       "      <td>0.464142</td>\n",
       "      <td>0.106891</td>\n",
       "      <td>1.520767</td>\n",
       "      <td>1.188540</td>\n",
       "      <td>-0.396697</td>\n",
       "      <td>-0.646966</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.794603</td>\n",
       "      <td>0.462929</td>\n",
       "      <td>0.101088</td>\n",
       "      <td>1.407372</td>\n",
       "      <td>-0.610101</td>\n",
       "      <td>-0.605965</td>\n",
       "      <td>1.954776</td>\n",
       "      <td>0.66003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>782762</td>\n",
       "      <td>-1</td>\n",
       "      <td>1194206.0</td>\n",
       "      <td>0.292299</td>\n",
       "      <td>0.365011</td>\n",
       "      <td>0.592555</td>\n",
       "      <td>0.188493</td>\n",
       "      <td>-3.397422</td>\n",
       "      <td>7.727718</td>\n",
       "      <td>-3.852727</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.278276</td>\n",
       "      <td>0.443328</td>\n",
       "      <td>0.532849</td>\n",
       "      <td>0.106909</td>\n",
       "      <td>7.720485</td>\n",
       "      <td>-6.933946</td>\n",
       "      <td>0.318971</td>\n",
       "      <td>0.66003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>927135</td>\n",
       "      <td>-1</td>\n",
       "      <td>1500421.0</td>\n",
       "      <td>0.574521</td>\n",
       "      <td>0.607894</td>\n",
       "      <td>0.297512</td>\n",
       "      <td>1.061868</td>\n",
       "      <td>-1.778870</td>\n",
       "      <td>-3.988987</td>\n",
       "      <td>-5.200574</td>\n",
       "      <td>0.403104</td>\n",
       "      <td>0.570212</td>\n",
       "      <td>0.564581</td>\n",
       "      <td>0.260894</td>\n",
       "      <td>0.474468</td>\n",
       "      <td>-4.142699</td>\n",
       "      <td>-2.794758</td>\n",
       "      <td>4.765884</td>\n",
       "      <td>0.66003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clump_id  Particle_id         X         Y         Z   Density  \\\n",
       "0      325643        -1     765198.0  0.998508  0.953404  0.897660  0.279144   \n",
       "1      492523        -1      22465.0  0.963346  0.239255  0.921146  1.553199   \n",
       "2     1411925        -1    1380389.0  0.778422  0.464142  0.106891  1.520767   \n",
       "3      782762        -1    1194206.0  0.292299  0.365011  0.592555  0.188493   \n",
       "4      927135        -1    1500421.0  0.574521  0.607894  0.297512  1.061868   \n",
       "\n",
       "         Vx        Vy        Vz    t_hard  O_Clump_X  O_Clump_Y  O_Clump_Z  \\\n",
       "0 -6.064194  0.293609 -1.328493  0.403104   0.932550   0.946430   0.891439   \n",
       "1 -4.098066  3.169495 -1.430379  0.403104   0.935869   0.267055   0.914330   \n",
       "2  1.188540 -0.396697 -0.646966  0.403104   0.794603   0.462929   0.101088   \n",
       "3 -3.397422  7.727718 -3.852727  0.403104   0.278276   0.443328   0.532849   \n",
       "4 -1.778870 -3.988987 -5.200574  0.403104   0.570212   0.564581   0.260894   \n",
       "\n",
       "   O_Clump_Vx  O_Clump_Vy  O_Clump_Vz  O_Clump_density  O_t_end  \n",
       "0   -7.100963   -0.826690   -0.527203         0.278950  0.66003  \n",
       "1   -1.835060    2.208904    0.159224         2.434835  0.66003  \n",
       "2    1.407372   -0.610101   -0.605965         1.954776  0.66003  \n",
       "3    0.106909    7.720485   -6.933946         0.318971  0.66003  \n",
       "4    0.474468   -4.142699   -2.794758         4.765884  0.66003  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATAFILE)\n",
    "print(len(df))\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 450x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_data():\n",
    "    \n",
    "    fig = plt.figure(figsize=(4.5, 4))\n",
    "    \n",
    "    ax  = fig.add_subplot(111)\n",
    "    \n",
    "    tickmarks = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xlabel('X', fontsize=18)\n",
    "    ax.set_xticks(tickmarks)\n",
    "    \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('Y', fontsize=18)\n",
    "    ax.set_yticks(tickmarks)\n",
    "    \n",
    "    d1 = df[df.Clump_id ==2]\n",
    "    xp, yp = d1.X[:1000], d1.Y[:1000]\n",
    "    ax.scatter(xp, yp, s=4.0, color='red')\n",
    "    \n",
    "    d2 = df[df.Clump_id ==31]\n",
    "    xp, yp = d2.X[:1000], d2.Y[:1000]\n",
    "    ax.scatter(xp, yp, s=4.0, color='royalblue');\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000\n",
      "100000\n",
      "397152\n"
     ]
    }
   ],
   "source": [
    "train_data  = df[:NTRAIN]\n",
    "print(len(train_data))\n",
    "\n",
    "valid_data  = df[NTRAIN:NTRAIN+NVALID]\n",
    "print(len(valid_data))\n",
    "\n",
    "test_data = df[NTRAIN+NVALID:]\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1600000, 8]), torch.Size([1600000, 8]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe2tensor(df, target, source):\n",
    "    # change from pandas dataframe to PyTorch tensors\n",
    "    # and load data to device.\n",
    "    x = torch.tensor(df[source].to_numpy()).float().to(DEVICE)\n",
    "    y = torch.tensor(df[target].to_numpy()).float().to(DEVICE)\n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = dataframe2tensor(train_data, TARGET, FEATURES)\n",
    "valid_x, valid_y = dataframe2tensor(valid_data, TARGET, FEATURES)\n",
    "test_x,  test_y  = dataframe2tensor(test_data,  TARGET, FEATURES)\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some ML Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(x, y, batch_size, ii):\n",
    "    # cycle through batches of training data sequentially\n",
    "    K = int(len(x) / batch_size + 0.5) # number of batches / epoch\n",
    "    jj = ii % K\n",
    "    start = jj * batch_size\n",
    "    end = start + batch_size - 1\n",
    "    if end > len(x)-1:\n",
    "        end = len(x)-1\n",
    "    return x[start: end+1], y[start: end+1], jj\n",
    "\n",
    "def get_random_batch(x, y, batch_size):\n",
    "    # selects at random \"batch_size\" integers from \n",
    "    # the range [0, batch_size-1] corresponding to the\n",
    "    # row indices of the training data\n",
    "    rows = torch.randint(0, len(x)-1, size=(batch_size,))\n",
    "    return x[rows], y[rows]\n",
    "        \n",
    "def validate(model, avloss, x, y):\n",
    "    # set to evaluation mode so that any training \n",
    "    # specific operations are disabled.\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # no need to compute gradients wrt. x and y\n",
    "        # reshape to ensure that f and y are of the same shape!\n",
    "        f = model(x).reshape(y.shape)\n",
    "    return avloss(f, y)\n",
    "\n",
    "def number_of_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def plot_loss_curve(losses,hyperparam):\n",
    "    \n",
    "    xx, yy_t, yy_v = losses\n",
    "    \n",
    "    # create an empty figure\n",
    "    fig = plt.figure(figsize=(5, 3.8))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    # add a subplot to it\n",
    "    nrows, ncols, index = 1,1,1\n",
    "    ax  = fig.add_subplot(nrows,ncols,index)\n",
    "    \n",
    "    ax.plot(xx, yy_t, color='red',  lw=1, label='training loss')\n",
    "    ax.plot(xx, yy_v, color='blue', lw=1, label='validation loss')\n",
    "    ax.set_title(\"H: \"+str(hyperparam))\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.set_xlabel('iterations')\n",
    "    ax.set_ylabel('average loss')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True, which=\"both\", linestyle='-')\n",
    "\n",
    "    name_str = ''\n",
    "    for hi in range(len(hyperparam)):\n",
    "        name_str += '_H'+str(hi+1)+'_'+str(hyperparam[hi])\n",
    "    plt.savefig(\"../../plots_to_sort/ANN_Losses/2_Layer_model\"+name_str+\".png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the fully-connected neural network\n",
    "\n",
    "### $\\texttt{ReLU}(x)$\n",
    "\n",
    "$$\\text{Relu}(x) = max(0, z)$$\n",
    "\n",
    "\n",
    "### LayerNorm\n",
    "\n",
    "$$y = \\frac{(x - E[x])}{\\sqrt{V(x)}},$$\n",
    "\n",
    "where the averaging is over the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile nnmodel.py\n",
    "def define_and_train_model(H=[2], n_iterations  = 25000, n_epochs = 1):\n",
    "    try:\n",
    "        del model\n",
    "    except:\n",
    "        print(\"No model to delete\")\n",
    "    import torch.nn as nn\n",
    "    n_input = 8\n",
    "    n_output = 8\n",
    "    #model = nn.Sequential(nn.Linear(n_input, H), nn.ReLU(), nn.BatchNorm1d(H), nn.Dropout(0.2),\n",
    "    #                    nn.Linear(H, 2*H), nn.ReLU(), nn.BatchNorm1d(2*H), nn.Dropout(0.3),\n",
    "    #                    nn.Linear(2*H, H), nn.ReLU(), nn.BatchNorm1d(H),\n",
    "    #                    nn.Linear(H, int(H/2)), nn.ReLU(),\n",
    "    #                    nn.Linear(int(H/2), n_output))\n",
    "    model = nn.Sequential(nn.Linear(n_input, H[0]), nn.ReLU(), nn.BatchNorm1d(H[0]), nn.Dropout(0.2),\n",
    "                        nn.Linear(H[0], H[1]), nn.ReLU(), nn.BatchNorm1d(H[1]), nn.Dropout(0.3),\n",
    "                        nn.Linear(H[1], n_output))\n",
    "    #from nnmodel import model\n",
    "\n",
    "    learning_rate = 1.e-4\n",
    "    optimizer     = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "\n",
    "    n_batch  = 32\n",
    "    n_step   = 10\n",
    "    n_valid  = len(valid_x)\n",
    "    train_x2 = train_x[:n_valid]\n",
    "    train_y2 = train_y[:n_valid]\n",
    "\n",
    "    emprisk  = nn.HuberLoss(delta=0.0005)\n",
    "    #print(number_of_parameters(model),model)\n",
    "    # Train model\n",
    "    USE_SEQUENTIAL_BATCHES = True\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    X = []\n",
    "    T = []\n",
    "    V = []\n",
    "\n",
    "    min_avloss = float('inf')\n",
    "\n",
    "    while epoch<n_epochs:\n",
    "        for ii in range(n_iterations):\n",
    "\n",
    "            # clear previous gradients\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # set mode to training so that training specific \n",
    "            # operations such as dropout are enabled.\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            # get a batch of data \n",
    "\n",
    "            if USE_SEQUENTIAL_BATCHES:\n",
    "                x, y, jj = get_batch(train_x, train_y, n_batch, ii)\n",
    "                if jj == 0:\n",
    "                    epoch += 1\n",
    "            else:\n",
    "                x, y = get_random_batch(train_x, train_y, n_batch)  \n",
    "            \n",
    "            f = model(x).reshape(y.shape)\n",
    "\n",
    "            R = emprisk(f, y)\n",
    "            \n",
    "            R.backward()  # compute gradients of with respect to NN parameters\n",
    "\n",
    "            optimizer.step()    # advance one step in the space of NN parameters\n",
    "\n",
    "            if ii % n_step == 0:\n",
    "                \n",
    "                t_loss = validate(model, emprisk, train_x2, train_y2).detach()\n",
    "                v_loss = validate(model, emprisk, valid_x,  valid_y).detach()\n",
    "\n",
    "                print(f'\\r|{epoch:9d}|{ii:9d}|{t_loss:9.3e}|{v_loss:9.3e}|', end='')\n",
    "\n",
    "                X.append(ii)\n",
    "                T.append(float(t_loss))\n",
    "                V.append(float(v_loss))\n",
    "\n",
    "                if v_loss < 0.995 * min_avloss:\n",
    "                    min_avloss = v_loss\n",
    "                    torch.save(model.state_dict(), MODELFILE)\n",
    "                \n",
    "        print()\n",
    "\n",
    "    plot_loss_curve([X, T, V], H)\n",
    "    return model,emprisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model to delete\n",
      "|        1|    24990|8.005e-02|8.125e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.007e-02|8.127e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.009e-02|8.128e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.012e-02|8.133e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.000e-02|8.121e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.008e-02|8.128e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.006e-02|8.126e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.012e-02|8.133e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.005e-02|8.125e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.013e-02|8.134e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.005e-02|8.125e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.014e-02|8.135e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.009e-02|8.130e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.008e-02|8.128e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.000e-02|8.120e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.008e-02|8.128e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.013e-02|8.133e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.004e-02|8.124e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.006e-02|8.127e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.011e-02|8.131e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.009e-02|8.129e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.018e-02|8.138e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.005e-02|8.125e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.003e-02|8.123e-02|\n",
      "No model to delete\n",
      "|        1|    24990|8.000e-02|8.120e-02|\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[5, 5], tensor(0.0776), np.float32(2482.8984), -1.6226172014719908],\n",
       " [[5, 6], tensor(0.0777), np.float32(2481.592), 0.25303606290128516],\n",
       " [[5, 7], tensor(0.0777), np.float32(2482.1487), -0.2996039180969296],\n",
       " [[5, 8], tensor(0.0777), np.float32(2482.1055), -0.5151293918434399],\n",
       " [[5, 9], tensor(0.0776), np.float32(2481.299), 0.2139441817724459],\n",
       " [[6, 5], tensor(0.0777), np.float32(2481.6353), -0.02578643653089019],\n",
       " [[6, 6], tensor(0.0777), np.float32(2481.8103), -0.021682744261394535],\n",
       " [[6, 7], tensor(0.0777), np.float32(2481.6094), -0.3780484029133032],\n",
       " [[6, 8], tensor(0.0776), np.float32(2481.4897), -0.0187348698969481],\n",
       " [[6, 9], tensor(0.0777), np.float32(2481.2527), 0.08423104313290207],\n",
       " [[7, 5], tensor(0.0776), np.float32(2481.6848), 0.127852157941224],\n",
       " [[7, 6], tensor(0.0777), np.float32(2481.371), 0.08874563881907689],\n",
       " [[7, 7], tensor(0.0777), np.float32(2481.769), -0.3337645075571757],\n",
       " [[7, 8], tensor(0.0777), np.float32(2481.8896), -0.3835855775659903],\n",
       " [[7, 9], tensor(0.0776), np.float32(2482.046), -0.23698374583740595],\n",
       " [[8, 5], tensor(0.0777), np.float32(2481.6895), 0.2040372077173051],\n",
       " [[8, 6], tensor(0.0777), np.float32(2482.344), -0.41923897432630597],\n",
       " [[8, 7], tensor(0.0776), np.float32(2481.6018), 0.1490480317474004],\n",
       " [[8, 8], tensor(0.0776), np.float32(2481.514), 0.09447191867876978],\n",
       " [[8, 9], tensor(0.0777), np.float32(2482.775), -0.9941299675513133],\n",
       " [[9, 5], tensor(0.0777), np.float32(2481.6267), 0.23490457260574021],\n",
       " [[9, 6], tensor(0.0777), np.float32(2482.9333), -1.8692165982114426],\n",
       " [[9, 7], tensor(0.0776), np.float32(2481.9531), -0.08543488364107164],\n",
       " [[9, 8], tensor(0.0776), np.float32(2481.5244), 0.11082370012629202],\n",
       " [[9, 9], tensor(0.0776), np.float32(2481.3228), 0.2354866550035964]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as skm\n",
    "best_model_arr = []\n",
    "#hyperparam_value H = 4 for 4 layer\n",
    "#hyperparam_value H = 2 for 3 layer\n",
    "#hyperparam_value H = 8 for 2 layer\n",
    "#hyperparam_value H = 8 for 1 layer\n",
    "#hyperparam_value H1,H2 = 5,9 for 2 layer\n",
    "\n",
    "for hyperparam_value1 in range(5,10):\n",
    "    for hyperparam_value2 in range(5,10):\n",
    "        model,emprisk = define_and_train_model([hyperparam_value1,hyperparam_value2])\n",
    "        # standard measures of model performance\n",
    "        # set to evaluation mode so that any training \n",
    "        # specific operations are disabled.\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # no need to compute gradients wrt. x and y\n",
    "            # reshape to ensure that f and y are of the same shape!\n",
    "            f = model(test_x).reshape(test_y.shape)\n",
    "        v_loss = emprisk(f, test_y).detach()\n",
    "        rmse = skm.root_mean_squared_error(test_y,f.detach())\n",
    "        r2 = skm.r2_score(test_y,f.detach())\n",
    "        best_model_arr.append([[hyperparam_value1,hyperparam_value2],v_loss,rmse,r2])\n",
    "best_model_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
