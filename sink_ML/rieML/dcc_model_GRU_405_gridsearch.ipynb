{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIEML DCC MODEL GRU to 405 Gridsearch to find optimum model\n",
    "> Created Aug. 2025 <br>\n",
    "> Nikhil Bisht<br>\n",
    "\n",
    "First pass sequence to GRU and then output of the sequence to 405 to predict output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cpu \n"
     ]
    }
   ],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "import h5py \n",
    "import argparse\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "# standard statistical module\n",
    "import scipy.stats as st\n",
    "from scipy import linalg\n",
    "from scipy.stats import ks_2samp\n",
    "import skimage as ski\n",
    "\n",
    "# standard module for high-quality plots\n",
    "from PIL import Image\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "mp.rcParams.update(mp.rcParamsDefault)\n",
    "%matplotlib inline\n",
    "\n",
    "# to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import tables\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "import plot\n",
    "import datetime\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "seed = 128\n",
    "rnd  = np.random.RandomState(seed)\n",
    "\n",
    "DATAFILE  = '/data/cb1/nbisht/anvil_scratch/projects/rieml/tubes_take8_time.h5'\n",
    "MODELFILE = 'nnmodel.dict'\n",
    "\n",
    "TEST_PERCENTAGE = 0.2\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Available device: {str(DEVICE):4s}')\n",
    "\n",
    "idd = 989\n",
    "what = \"909 then 405 dilation 9 with gridsearch\"\n",
    "testnum=idd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_constant(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        #nn.init.constant_(m.weight, 0.5)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "\n",
    "def thisnet(layers, kernels, hidden_dims, bias, output_type):\n",
    "    input_sequence_time_length = 2\n",
    "    num_layers_GRU = layers\n",
    "    kernels_GRU = kernels\n",
    "    hidden_dims_GRU = hidden_dims\n",
    "    hidden_dims_dcc = 256,\n",
    "    conv_channels_dcc = 32\n",
    "    model = hybridNET(in_seq=input_sequence_time_length, num_layers=num_layers_GRU, kernels = kernels_GRU, hidden_dims = hidden_dims_GRU, \n",
    "                      bias = bias, output_type = output_type, hidden_dims_dcc = hidden_dims_dcc, conv_channels_dcc = conv_channels_dcc)\n",
    "    return model\n",
    "\n",
    "def train(model,data,parameters, validatedata, validateparams, modellevel=1, model_name='model'):\n",
    "    epochs = 60000\n",
    "    lr = 1e-3\n",
    "    batch_size=3\n",
    "    w_d = 0.01\n",
    "    mean_ve, std_ve, min_ve, max_ve = trainer(model,data,parameters,validatedata,validateparams,epochs=epochs,lr=lr,batch_size=batch_size, weight_decay = w_d, modellevel=modellevel, model_name=model_name)\n",
    "    return mean_ve, std_ve, min_ve, max_ve\n",
    "\n",
    "\n",
    "def trainer(model, x_train ,y_train, x_validate, y_validate, epochs=1, lr=1e-3, batch_size=10, test_num=0, weight_decay=0.01, modellevel=1, model_name='model'):\n",
    "    optimizer = optim.AdamW( model.parameters(), lr=lr,weight_decay =weight_decay )\n",
    "    from torch.optim.lr_scheduler import CyclicLR\n",
    "    scheduler = CyclicLR(\n",
    "            optimizer,\n",
    "            base_lr=1e-7,\n",
    "            max_lr=1e-3,\n",
    "            step_size_up=30000,\n",
    "            mode='triangular',   # or 'triangular2', 'exp_range'\n",
    "            cycle_momentum=False # if you use Adam, turn this off\n",
    "    )\n",
    "    losses=[]\n",
    "    a = torch.arange(x_train.shape[0])\n",
    "    seed = 8675309\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    t0 = time.time()\n",
    "    minlist=[];meanlist=[];maxlist=[];stdlist=[]\n",
    "    for epoch in range(epochs):\n",
    "        subset = torch.tensor(random.sample(list(a),batch_size))\n",
    "        x_subset =  x_train[subset]\n",
    "        y_subset = y_train[subset]\n",
    "        optimizer.zero_grad()\n",
    "        output1=model(x_subset)\n",
    "        loss = model.criterion(output1, y_subset)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        tnow = time.time()\n",
    "        tel = tnow-t0\n",
    "        if (epoch>0 and epoch%100==0) or epoch==10:\n",
    "            model.eval()\n",
    "            validate_losses = plot.compute_losses_gru(model, x_validate, y_validate)\n",
    "            model.train()\n",
    "\n",
    "            time_per_epoch = tel/epoch\n",
    "            epoch_remaining = epochs-epoch\n",
    "            time_remaining_s = time_per_epoch*epoch_remaining\n",
    "            eta = tnow+time_remaining_s\n",
    "            etab = datetime.datetime.fromtimestamp(eta)\n",
    "\n",
    "            if 1:\n",
    "                hrs = time_remaining_s//3600\n",
    "                minute = (time_remaining_s-hrs*3600)//60\n",
    "                sec = (time_remaining_s - hrs*3600-minute*60)#//60\n",
    "                time_remaining=\"%02d:%02d:%02d\"%(hrs,minute,sec)\n",
    "            if 1:\n",
    "                eta = \"%0.2d:%0.2d:%0.2d\"%(etab.hour, etab.minute, int(etab.second))\n",
    "\n",
    "            mean = validate_losses.mean()\n",
    "            std = validate_losses.std()\n",
    "            mmin = validate_losses.min()\n",
    "            mmax = validate_losses.max()\n",
    "            minlist.append(mmin)\n",
    "            maxlist.append(mmax)\n",
    "            meanlist.append(mean)\n",
    "            stdlist.append(std)\n",
    "            if epoch == 10:\n",
    "                print(\"test %s %d L %0.2e LR %0.2e left %8s  eta %8s loss mean %0.2e var %0.2e min %0.2e max %0.2e\"%\n",
    "                    (model_name,epoch,loss, optimizer.param_groups[0]['lr'],time_remaining, eta, mean, std, mmin, mmax))\n",
    "    print(\"Run time\", tel)\n",
    "    plt.clf()\n",
    "    plt.plot(meanlist,c='k')\n",
    "    plt.plot(np.array(meanlist)+np.array(stdlist),c='b')\n",
    "    plt.plot(np.array(meanlist)-np.array(stdlist),c='b')\n",
    "    plt.plot(minlist,c='r')\n",
    "    plt.plot(maxlist,c='r')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig('./gridsearch_plots/level'+str(modellevel)+'_models/errortime_test_'+model_name+'.png')\n",
    "    return min(meanlist[-1000:]), min(stdlist[-1000:]), min(minlist[-1000:]), min(maxlist[-1000:])\n",
    "\n",
    "\n",
    "class hybridNET(nn.Module):\n",
    "    def __init__(self, in_seq = 2, out_seq = 1, arr_length=1000, phys_params = 3, num_layers = 1, kernels = [3], hidden_dims = [16], bias = True, output_type = 'reduced', return_all_layers = False, hidden_dims_dcc = 256, conv_channels_dcc = 32):\n",
    "        \"\"\"\n",
    "        Initialize the hybridNET model\n",
    "        :param in_seq: int\n",
    "            Number of input sequences, how many time states given\n",
    "        :param out_seq: int\n",
    "            Number of output sequences, how many time states to predict\n",
    "        :param arr_length: int\n",
    "            length of the 1D array for a physical parameter\n",
    "        :param phys_params: int\n",
    "            Number of physical parameters inputted, 3 = Density, Pressure, Velocity_x\n",
    "        :param num_layers: int\n",
    "            number of layers in GRU\n",
    "        :param kernels: (int,int,...)\n",
    "            kernel size for each layer\n",
    "        :param hidden_dims: (int,int,...)\n",
    "            channel size for each layer\n",
    "        :param hidden_dims_dcc: (int,int,...)\n",
    "            channel size for each layer of 405 network\n",
    "        :param conv_channels_dcc: (nt\n",
    "            channel size for hidden layer of 405 net\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_seq = in_seq\n",
    "        self.out_seq = out_seq\n",
    "        self.arr_length = arr_length\n",
    "        self.phys_params = phys_params\n",
    "        self.num_layers = num_layers\n",
    "        self.kernels = kernels\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.bias = bias\n",
    "        self.output_type = output_type\n",
    "        self.return_all_layers = return_all_layers\n",
    "        self.hidden_dims_dcc = hidden_dims_dcc\n",
    "        self.conv_channels_dcc = conv_channels_dcc\n",
    "\n",
    "        self.ConvGRUNet = ConvGRUNet(in_seq = self.in_seq, out_seq = self.out_seq, arr_length=self.arr_length, phys_params = self.phys_params, num_layers = self.num_layers, kernels = self.kernels, \n",
    "                                     hidden_dims = self.hidden_dims, bias = self.bias, output_type = self.output_type, return_all_layers = self.return_all_layers)\n",
    "        self.dccNET = DCC_NNet(output_length=self.arr_length, hidden_dims=self.hidden_dims_dcc, conv_channels=self.conv_channels_dcc, characteristic=False)\n",
    "        self.l1 = nn.L1Loss()\n",
    "\n",
    "    def criterion(self,guess,target, initial=None):\n",
    "        L1 = self.l1(target,guess)\n",
    "        return L1\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        :param input_tensor: (b, t_in, c, l)\n",
    "        :param hidden_state:\n",
    "        :return: output_tensor: (b, t_out, c, l)\n",
    "        \"\"\"\n",
    "        GRU_output = self.ConvGRUNet(input_tensor)  #(b, t_out, c, l)\n",
    "        dcc_output = self.dccNET(GRU_output[:,0,:,:]) #(b, c, l)\n",
    "        return dcc_output[:,None,:,:]\n",
    "        \n",
    "\n",
    "class ConvGRUNet(nn.Module):\n",
    "    def __init__(self, in_seq = 2, out_seq = 1, arr_length=1000, phys_params = 3, num_layers = 1, kernels = [3], hidden_dims = [16], bias = True, output_type = 'reduced', return_all_layers = False):\n",
    "        \"\"\"\n",
    "        Initialize the ConvGRU model\n",
    "        :param in_seq: int\n",
    "            Number of input sequences, how many time states given\n",
    "        :param out_seq: int\n",
    "            Number of output sequences, how many time states to predict\n",
    "        :param arr_length: int\n",
    "            length of the 1D array for a physical parameter\n",
    "        :param phys_params: int\n",
    "            Number of physical parameters inputted, 3 = Density, Pressure, Velocity_x\n",
    "        :param num_layers: int\n",
    "            number of layers in GRU\n",
    "        :param kernels: (int,int,...)\n",
    "            kernel size for each layer\n",
    "        :param hidden_dims: (int,int,...)\n",
    "            channel size for each layer\n",
    "        :param bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        :param output_type: str\n",
    "            Type of output, 'reduced' for reduced output, 'final' for last cell output\n",
    "        :param return_all_layers: bool\n",
    "            Whether to return all layers or just the last layer output\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_seq = in_seq\n",
    "        self.out_seq = out_seq\n",
    "        self.arr_length = arr_length\n",
    "        self.phys_params = phys_params\n",
    "        self.num_layers = num_layers\n",
    "        self.kernels = kernels\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.bias = bias\n",
    "        self.output_type = output_type\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        #check condition\n",
    "        if not (len(self.kernels)==len(self.hidden_dims) and len(self.kernels)==num_layers):\n",
    "            raise ValueError(\"kernel and hidden layer lists don't match number of layers!\")\n",
    "        \n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.phys_params if i == 0 else self.hidden_dims[i - 1]\n",
    "            cell_list.append(ConvGRUCell(input_length=self.arr_length,\n",
    "                                         phys_params=cur_input_dim,\n",
    "                                         hidden_dim=self.hidden_dims[i],\n",
    "                                         kernel_size=self.kernels[i],\n",
    "                                         bias=self.bias))\n",
    "\n",
    "        # convert python list to pytorch module\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "        if self.output_type == 'reduced':\n",
    "            self.out_linear = nn.Linear(self.in_seq,self.out_seq, bias = self.bias)\n",
    "\n",
    "        self.out_cnn = nn.Conv1d(in_channels=self.hidden_dims[-1],\n",
    "                                    out_channels=self.phys_params,\n",
    "                                    kernel_size=self.kernels[-1],\n",
    "                                    padding=self.kernels[-1]//2,\n",
    "                                    bias=self.bias,\n",
    "                                    padding_mode='reflect')\n",
    "\n",
    "        self.mse=nn.MSELoss()\n",
    "        self.log_derivative_weight = nn.Parameter(torch.tensor(0.0)) \n",
    "        self.hl = nn.HuberLoss(delta=0.2)\n",
    "        self.l1 = nn.L1Loss()\n",
    "\n",
    "    def criterion(self,guess,target, initial=None):\n",
    "        L1 = self.l1(target,guess)\n",
    "        return L1\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        :param input_tensor: (b, t_in, c, l)\n",
    "        :param hidden_state:\n",
    "        :return: output_tensor: (b, t_out, c, l)\n",
    "        \"\"\"\n",
    "        hidden_state = self._init_hidden(batch_size=input_tensor.size(0))\n",
    "\n",
    "        layer_output_list = []\n",
    "        cur_layer_input = input_tensor\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            h = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(self.in_seq):\n",
    "                # input current hidden and cell state then compute the next hidden and cell state through ConvGRU forward function\n",
    "                h = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :], #(b,t,c,l)\n",
    "                                              h_cur=h)\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "        \n",
    "        last_layer_output = layer_output_list[-1] # shape (b,t_in,h,l)\n",
    "        if self.output_type == 'final':\n",
    "            out_arr = last_layer_output[:,-1,:,:] # shape (b,h,l)\n",
    "            out_arr = self.out_cnn(out_arr)[:,None,:,:] # shape (b,t_out,c,l)\n",
    "        elif self.output_type == 'reduced':\n",
    "            last_layer_output = last_layer_output.permute(0,2,3,1) # shape (b,h,l,t_in)\n",
    "            #Now linear over time domain\n",
    "            last_layer_output = self.out_linear(last_layer_output) # shape (b,h,l,t_out)\n",
    "            last_layer_output = last_layer_output.permute(0,3,1,2) # shape (b,t_out,h,l)\n",
    "            #now iterate over output channels and convolve one last time\n",
    "            out_arr = []\n",
    "            for tout_idx in range(self.out_seq):\n",
    "                out_arr.append(self.out_cnn(last_layer_output[:,tout_idx,:,:])) # shape (b,c,l) for a t\n",
    "            \n",
    "            out_arr = torch.stack(out_arr, dim=1)               # shape (b,t_out,c,l)\n",
    "        else:\n",
    "            raise ValueError(\"output_type must be 'reduced' or 'final'!\")\n",
    "        \n",
    "        if self.return_all_layers:\n",
    "            return layer_output_list, out_arr\n",
    "        else:\n",
    "            return out_arr\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size))\n",
    "        return init_states\n",
    "\n",
    "\n",
    "class ConvGRUCell(nn.Module):\n",
    "    def __init__(self, input_length, phys_params, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize a ConvGRU cell\n",
    "        :param input_length: int\n",
    "            length of the output 1D array for a physical parameter\n",
    "        :param phys_params: int\n",
    "            Number of physical parameters inputted, 3 = Density, Pressure, Velocity_x\n",
    "        :param hidden_dim: int\n",
    "            Number of channels of hidden state\n",
    "        :param kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        :param bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "        super(ConvGRUCell, self).__init__()\n",
    "        self.length = input_length\n",
    "        self.phys_params = phys_params\n",
    "        self.padding = kernel_size // 2\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv_gates = nn.Conv1d(in_channels=self.phys_params + self.hidden_dim,\n",
    "                                    out_channels=2*self.hidden_dim,  # for update_gate,reset_gate respectively\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    padding=self.padding,\n",
    "                                    bias=self.bias,\n",
    "                                    padding_mode='reflect')\n",
    "\n",
    "        self.conv_can = nn.Conv1d(in_channels=self.phys_params + self.hidden_dim,\n",
    "                              out_channels=self.hidden_dim, # for candidate neural memory\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias,\n",
    "                              padding_mode='reflect')\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_dim, self.length)\n",
    "\n",
    "    def forward(self, input_tensor, h_cur):\n",
    "        \"\"\"\n",
    "        :param self:\n",
    "        :param input_tensor: (b, c, l)\n",
    "            input is actually the target_model\n",
    "        :param h_cur: (b, c_hidden, l)\n",
    "            current hidden state\n",
    "        :return: h_next\n",
    "            next hidden state\n",
    "        \"\"\"\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)\n",
    "        combined_conv = self.conv_gates(combined)\n",
    "\n",
    "        gamma, beta = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        reset_gate = torch.sigmoid(gamma)\n",
    "        update_gate = torch.sigmoid(beta)\n",
    "\n",
    "        combined = torch.cat([input_tensor, reset_gate*h_cur], dim=1)\n",
    "        cc_cnm = self.conv_can(combined)\n",
    "        cnm = torch.tanh(cc_cnm)\n",
    "\n",
    "        h_next = (1 - update_gate) * h_cur + update_gate * cnm\n",
    "        return h_next\n",
    "\n",
    "\n",
    "class DCC_NNet(nn.Module):\n",
    "    def __init__(self, output_length=1000, hidden_dims=(128, 128), conv_channels=32, characteristic=False):\n",
    "        super().__init__()\n",
    "        self.output_length = output_length\n",
    "\n",
    "        # Project 6 input values to a pseudo-spatial format (3 channels)\n",
    "        #self.fc1 = nn.Linear(7, 3 * output_length)\n",
    "        #self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Conv block 1 (acts on the \"3 x output_length\" format)\n",
    "        dil = 1\n",
    "        kern = 5\n",
    "        padding = dil*(kern-1)//2\n",
    "        dil2 = 2\n",
    "        padding2 = dil2*(kern-1)//2\n",
    "        dil3 = 4\n",
    "        padding3 = dil3*(kern-1)//2\n",
    "        dil4 = 8\n",
    "        padding4 = dil4*(kern-1)//2\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(3, conv_channels, kernel_size=kern, padding=padding, dilation=dil),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(conv_channels, 3, kernel_size=kern, padding=padding, dilation=dil),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # FC block 2: merge spatial info\n",
    "        in_dim = 3*output_length\n",
    "        out_dim = 3*output_length\n",
    "        layers=[]\n",
    "        dims = [in_dim] + list(hidden_dims) + [out_dim]\n",
    "        for i in range(len(dims)-1):\n",
    "            layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "            if i < len(dims) - 2:\n",
    "                layers.append(nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(*layers)\n",
    "\n",
    "        # Conv block 2\n",
    "        dil = 1\n",
    "        kern = 3\n",
    "        padding = dil*(kern-1)//2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(3, conv_channels, kernel_size=kern, padding=padding, dilation=dil),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(conv_channels, 3, kernel_size=kern, padding=padding, dilation=dil)\n",
    "        )\n",
    "        dil1 = 2\n",
    "        kern1 = 3\n",
    "        padding1 = dil1*(kern1-1)//2\n",
    "        dil2 = 2\n",
    "        kern2 = 3\n",
    "        padding2 = dil2*(kern2-1)//2\n",
    "        dil3 = 5\n",
    "        kern3 = 7\n",
    "        padding3 = dil3*(kern3-1)//2\n",
    "        self.conv3a = nn.Sequential(\n",
    "            nn.Conv1d(3, conv_channels, kernel_size=kern1, padding=padding1, dilation=dil1),\n",
    "            nn.ReLU())\n",
    "        self.conv3b = nn.Sequential(\n",
    "            nn.Conv1d(conv_channels, 2*conv_channels, kernel_size=kern2, padding=padding2, dilation=dil2),\n",
    "            nn.ReLU())\n",
    "        self.conv3e = nn.Sequential(\n",
    "            nn.Conv1d(2*conv_channels, conv_channels, kernel_size=kern2, padding=padding2, dilation=dil2),\n",
    "            nn.ReLU())\n",
    "        self.convdone = nn.Sequential(\n",
    "            nn.Conv1d(conv_channels, 3, kernel_size=kern1, padding=padding1, dilation=dil1)\n",
    "        )\n",
    "        self.conv1.apply(init_weights_constant)\n",
    "        self.conv2.apply(init_weights_constant)\n",
    "        self.conv3a.apply(init_weights_constant)\n",
    "        self.conv3b.apply(init_weights_constant)\n",
    "        self.conv3e.apply(init_weights_constant)\n",
    "        self.convdone.apply(init_weights_constant)\n",
    "        self.fc2.apply(init_weights_constant)\n",
    "        #self.fc1.apply(init_weights_constant)\n",
    "\n",
    "        self.T = nn.Parameter(torch.eye(3) + 0.01 * torch.randn(3, 3)) \n",
    "\n",
    "        self.mse=nn.MSELoss()\n",
    "        self.log_derivative_weight = nn.Parameter(torch.tensor(0.0)) \n",
    "\n",
    "        embed_dim=output_length\n",
    "        num_heads = 4\n",
    "        self.hl = nn.HuberLoss(delta=0.2)\n",
    "        self.l1 = nn.L1Loss()\n",
    "\n",
    "\n",
    "\n",
    "    def criterion(self,guess,target, initial=None):\n",
    "        L1 = self.l1(target,guess)\n",
    "        return L1\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size=x.shape[0]\n",
    "        # FC1 to expand global features into spatial representation\n",
    "        #x = self.fc1(x)  # (batch_size, 3*output_length)\n",
    "        #x = self.relu1(x)\n",
    "        #x = x.view(batch_size, 3, self.output_length)  # shape (B, 3, L)\n",
    "\n",
    "        # Conv block 1: local patterns\n",
    "        x = x + self.conv1(x)  # Residual connection\n",
    "\n",
    "        # FC2 block: reprocess globally\n",
    "        x_flat = x.view(batch_size, -1)\n",
    "        x_flat = self.fc2(x_flat)\n",
    "        x = x_flat.view(batch_size,3, self.output_length)\n",
    "\n",
    "        # Conv block 2: refine locally again\n",
    "        x = x + self.conv2(x)\n",
    "        x1 = self.conv3a(x)\n",
    "        x2 = self.conv3b(x1)\n",
    "        x5 =x1+ self.conv3e(x2)\n",
    "        z = x+self.convdone(x5)\n",
    "    \n",
    "\n",
    "        return z  # shape (B, 3, output_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 10]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import plot\n",
    "reload(plot)\n",
    "\n",
    "import tube_loader\n",
    "\n",
    "def get_data(in_seq = 2, dilation = 1, out_seq = 1, nvalid=50, ntest=100):\n",
    "    '''\n",
    "    in_seq: number of input time snapshots\n",
    "    dilation: how many snapshots ahead to predict\n",
    "    out_seq: number of output snapshots\n",
    "    '''\n",
    "    seq_l = in_seq+(dilation-1)+out_seq\n",
    "    rieml_data, parameters= tube_loader.read_all_parameters(DATAFILE)\n",
    "    reshaped_data = rieml_data.reshape(3000,11,3,1000)\n",
    "    sequenced_data = np.array([]).reshape(0,3,3,1000)\n",
    "    for i in range(11-seq_l+1):\n",
    "        time_indices_in = [j for j in range(i,i+in_seq)]\n",
    "        time_indices_out = [j for j in range(i+in_seq+dilation-1,i+in_seq+dilation-1+out_seq)]\n",
    "        time_indices_in.extend(time_indices_out)\n",
    "        time_indices = time_indices_in\n",
    "        print(time_indices)\n",
    "        sequenced_data = np.concatenate((sequenced_data,reshaped_data[:,time_indices,:,:]), axis=0)\n",
    "    #shuffle dataset\n",
    "    shuffled_indices = torch.randperm(sequenced_data.shape[0])\n",
    "    sequenced_data_shuffled = torch.index_select(torch.from_numpy(sequenced_data), dim=0, index=shuffled_indices)\n",
    "    len_seq = sequenced_data_shuffled.shape[0]\n",
    "    ntrain = len_seq-nvalid-ntest\n",
    "    # Split the tensor\n",
    "    train_dataset, test_dataset, validation_dataset = torch.split(sequenced_data_shuffled.float(), [ntrain,ntest,nvalid], dim=0)\n",
    "    X = {'train': train_dataset[:,0:2,:,:], 'test': test_dataset[:,0:2,:,:], 'validate': validation_dataset[:,0:2,:,:]}\n",
    "    y = {'train': train_dataset[:,2,:,:][:, None, :, :], 'test': test_dataset[:,2,:,:][:, None, :, :], 'validate': validation_dataset[:,2,:,:][:, None, :, :]}\n",
    "    return X,y\n",
    "\n",
    "rieml_data_seq, parameters_seq = get_data(in_seq = 2, dilation = 9, out_seq = 1, nvalid=50, ntest=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_search_space_layer_one():\n",
    "    \"\"\"\n",
    "    Define the search space for hyperparameter tuning for layer one. Bigger space to see what types of models work best.\n",
    "    Returns:\n",
    "        A dictionary containing the search space parameters.\n",
    "    \"\"\"\n",
    "    search_space = {\n",
    "        'bias': [True, False],\n",
    "        'output_type': ['reduced', 'final'],\n",
    "        #'layers': [1,2,3,4],\n",
    "        'kernels': [3, 5, 7, 9],\n",
    "        'hidden_dims': [8, 16, 32, 64, 128]\n",
    "    }\n",
    "\n",
    "    return search_space\n",
    "\n",
    "def model_search_space():\n",
    "    \"\"\"\n",
    "    Define the search space for hyperparameter tuning for higher layers. Smaller space to reduce computation time.\n",
    "    Returns:\n",
    "        A dictionary containing the search space parameters.\n",
    "    \"\"\"\n",
    "    search_space = {\n",
    "        'bias': [True, False],\n",
    "        'output_type': ['final'],\n",
    "        'kernels': [3, 5, 9],\n",
    "        'hidden_dims': [16, 32, 64]\n",
    "    }\n",
    "\n",
    "    return search_space\n",
    "\n",
    "def all_models(layers):\n",
    "    \"\"\"\n",
    "    Generate all combinations of hyperparameters for a given number of layers [1,2,3,4].\n",
    "    Returns:\n",
    "        A table containing a unique combination of hyperparameters as rows.\n",
    "    \"\"\"\n",
    "    search_space = model_search_space()\n",
    "    combinations = []\n",
    "    import itertools\n",
    "    all_kernels = list(itertools.product(search_space['kernels'], repeat=layers))\n",
    "    all_hidden_dims = list(itertools.product(search_space['hidden_dims'], repeat=layers))\n",
    "    i = 0\n",
    "    for bi in range(len(search_space['bias'])):\n",
    "        for ot in range(len(search_space['output_type'])):\n",
    "            for ke in range(len(all_kernels)):\n",
    "                for hi in range(len(all_hidden_dims)):\n",
    "                    model_param = {\n",
    "                        'model_name': 'model_'+str(i),\n",
    "                        'layers': layers,\n",
    "                        'bias': search_space['bias'][bi],\n",
    "                        'output_type': search_space['output_type'][ot],\n",
    "                        'kernels': list(all_kernels[ke]),\n",
    "                        'hidden_dims': list(all_hidden_dims[hi])\n",
    "                    }\n",
    "                    combinations.append(model_param)\n",
    "                    i += 1\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(combinations)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model_name': 'model_0', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [16, 16]}, {'model_name': 'model_1', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [16, 32]}, {'model_name': 'model_2', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [16, 64]}, {'model_name': 'model_3', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [32, 16]}, {'model_name': 'model_4', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [32, 32]}, {'model_name': 'model_5', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [32, 64]}, {'model_name': 'model_6', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [64, 16]}, {'model_name': 'model_7', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [64, 32]}, {'model_name': 'model_8', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [64, 64]}, {'model_name': 'model_9', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [16, 16]}, {'model_name': 'model_10', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [16, 32]}, {'model_name': 'model_11', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [16, 64]}, {'model_name': 'model_12', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [32, 16]}, {'model_name': 'model_13', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [32, 32]}, {'model_name': 'model_14', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [32, 64]}, {'model_name': 'model_15', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [64, 16]}, {'model_name': 'model_16', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [64, 32]}, {'model_name': 'model_17', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [64, 64]}, {'model_name': 'model_18', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [16, 16]}, {'model_name': 'model_19', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [16, 32]}, {'model_name': 'model_20', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [16, 64]}, {'model_name': 'model_21', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [32, 16]}, {'model_name': 'model_22', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [32, 32]}, {'model_name': 'model_23', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [32, 64]}, {'model_name': 'model_24', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [64, 16]}, {'model_name': 'model_25', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [64, 32]}, {'model_name': 'model_26', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [64, 64]}, {'model_name': 'model_27', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [16, 16]}, {'model_name': 'model_28', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [16, 32]}, {'model_name': 'model_29', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [16, 64]}, {'model_name': 'model_30', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [32, 16]}, {'model_name': 'model_31', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [32, 32]}, {'model_name': 'model_32', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [32, 64]}, {'model_name': 'model_33', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [64, 16]}, {'model_name': 'model_34', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [64, 32]}, {'model_name': 'model_35', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [64, 64]}, {'model_name': 'model_36', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [16, 16]}, {'model_name': 'model_37', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [16, 32]}, {'model_name': 'model_38', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [16, 64]}, {'model_name': 'model_39', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [32, 16]}, {'model_name': 'model_40', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [32, 32]}, {'model_name': 'model_41', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [32, 64]}, {'model_name': 'model_42', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [64, 16]}, {'model_name': 'model_43', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [64, 32]}, {'model_name': 'model_44', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [64, 64]}, {'model_name': 'model_45', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [16, 16]}, {'model_name': 'model_46', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [16, 32]}, {'model_name': 'model_47', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [16, 64]}, {'model_name': 'model_48', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [32, 16]}, {'model_name': 'model_49', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [32, 32]}, {'model_name': 'model_50', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [32, 64]}, {'model_name': 'model_51', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [64, 16]}, {'model_name': 'model_52', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [64, 32]}, {'model_name': 'model_53', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [64, 64]}, {'model_name': 'model_54', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [16, 16]}, {'model_name': 'model_55', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [16, 32]}, {'model_name': 'model_56', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [16, 64]}, {'model_name': 'model_57', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [32, 16]}, {'model_name': 'model_58', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [32, 32]}, {'model_name': 'model_59', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [32, 64]}, {'model_name': 'model_60', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [64, 16]}, {'model_name': 'model_61', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [64, 32]}, {'model_name': 'model_62', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [64, 64]}, {'model_name': 'model_63', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [16, 16]}, {'model_name': 'model_64', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [16, 32]}, {'model_name': 'model_65', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [16, 64]}, {'model_name': 'model_66', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [32, 16]}, {'model_name': 'model_67', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [32, 32]}, {'model_name': 'model_68', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [32, 64]}, {'model_name': 'model_69', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [64, 16]}, {'model_name': 'model_70', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [64, 32]}, {'model_name': 'model_71', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [64, 64]}, {'model_name': 'model_72', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [16, 16]}, {'model_name': 'model_73', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [16, 32]}, {'model_name': 'model_74', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [16, 64]}, {'model_name': 'model_75', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [32, 16]}, {'model_name': 'model_76', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [32, 32]}, {'model_name': 'model_77', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [32, 64]}, {'model_name': 'model_78', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [64, 16]}, {'model_name': 'model_79', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [64, 32]}, {'model_name': 'model_80', 'layers': 2, 'bias': True, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [64, 64]}, {'model_name': 'model_81', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [16, 16]}, {'model_name': 'model_82', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [16, 32]}, {'model_name': 'model_83', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [16, 64]}, {'model_name': 'model_84', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [32, 16]}, {'model_name': 'model_85', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [32, 32]}, {'model_name': 'model_86', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [32, 64]}, {'model_name': 'model_87', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [64, 16]}, {'model_name': 'model_88', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [64, 32]}, {'model_name': 'model_89', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 3], 'hidden_dims': [64, 64]}, {'model_name': 'model_90', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [16, 16]}, {'model_name': 'model_91', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [16, 32]}, {'model_name': 'model_92', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [16, 64]}, {'model_name': 'model_93', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [32, 16]}, {'model_name': 'model_94', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [32, 32]}, {'model_name': 'model_95', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [32, 64]}, {'model_name': 'model_96', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [64, 16]}, {'model_name': 'model_97', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [64, 32]}, {'model_name': 'model_98', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 5], 'hidden_dims': [64, 64]}, {'model_name': 'model_99', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [16, 16]}, {'model_name': 'model_100', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [16, 32]}, {'model_name': 'model_101', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [16, 64]}, {'model_name': 'model_102', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [32, 16]}, {'model_name': 'model_103', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [32, 32]}, {'model_name': 'model_104', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [32, 64]}, {'model_name': 'model_105', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [64, 16]}, {'model_name': 'model_106', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [64, 32]}, {'model_name': 'model_107', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [3, 9], 'hidden_dims': [64, 64]}, {'model_name': 'model_108', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [16, 16]}, {'model_name': 'model_109', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [16, 32]}, {'model_name': 'model_110', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [16, 64]}, {'model_name': 'model_111', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [32, 16]}, {'model_name': 'model_112', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [32, 32]}, {'model_name': 'model_113', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [32, 64]}, {'model_name': 'model_114', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [64, 16]}, {'model_name': 'model_115', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [64, 32]}, {'model_name': 'model_116', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 3], 'hidden_dims': [64, 64]}, {'model_name': 'model_117', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [16, 16]}, {'model_name': 'model_118', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [16, 32]}, {'model_name': 'model_119', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [16, 64]}, {'model_name': 'model_120', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [32, 16]}, {'model_name': 'model_121', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [32, 32]}, {'model_name': 'model_122', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [32, 64]}, {'model_name': 'model_123', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [64, 16]}, {'model_name': 'model_124', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [64, 32]}, {'model_name': 'model_125', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 5], 'hidden_dims': [64, 64]}, {'model_name': 'model_126', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [16, 16]}, {'model_name': 'model_127', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [16, 32]}, {'model_name': 'model_128', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [16, 64]}, {'model_name': 'model_129', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [32, 16]}, {'model_name': 'model_130', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [32, 32]}, {'model_name': 'model_131', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [32, 64]}, {'model_name': 'model_132', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [64, 16]}, {'model_name': 'model_133', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [64, 32]}, {'model_name': 'model_134', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [5, 9], 'hidden_dims': [64, 64]}, {'model_name': 'model_135', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [16, 16]}, {'model_name': 'model_136', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [16, 32]}, {'model_name': 'model_137', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [16, 64]}, {'model_name': 'model_138', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [32, 16]}, {'model_name': 'model_139', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [32, 32]}, {'model_name': 'model_140', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [32, 64]}, {'model_name': 'model_141', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [64, 16]}, {'model_name': 'model_142', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [64, 32]}, {'model_name': 'model_143', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 3], 'hidden_dims': [64, 64]}, {'model_name': 'model_144', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [16, 16]}, {'model_name': 'model_145', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [16, 32]}, {'model_name': 'model_146', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [16, 64]}, {'model_name': 'model_147', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [32, 16]}, {'model_name': 'model_148', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [32, 32]}, {'model_name': 'model_149', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [32, 64]}, {'model_name': 'model_150', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [64, 16]}, {'model_name': 'model_151', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [64, 32]}, {'model_name': 'model_152', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 5], 'hidden_dims': [64, 64]}, {'model_name': 'model_153', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [16, 16]}, {'model_name': 'model_154', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [16, 32]}, {'model_name': 'model_155', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [16, 64]}, {'model_name': 'model_156', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [32, 16]}, {'model_name': 'model_157', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [32, 32]}, {'model_name': 'model_158', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [32, 64]}, {'model_name': 'model_159', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [64, 16]}, {'model_name': 'model_160', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [64, 32]}, {'model_name': 'model_161', 'layers': 2, 'bias': False, 'output_type': 'final', 'kernels': [9, 9], 'hidden_dims': [64, 64]}]\n",
      "Number of models in search space for 2 layers: 162\n",
      "test model_0 10 L 7.09e-01 LR 4.67e-07 left 00:20:02  eta 11:11:33 loss mean 6.31e-01 var 1.50e-01 min 3.53e-01 max 9.79e-01\n"
     ]
    }
   ],
   "source": [
    "layers = 2\n",
    "all_model_df = all_models(layers)\n",
    "print(f\"Number of models in search space for {layers} layers: {len(all_model_df)}\")\n",
    "for i in range(len(all_model_df)):\n",
    "    model_params = all_model_df.iloc[i]\n",
    "    model = thisnet(layers=model_params['layers'], kernels=model_params['kernels'], hidden_dims=model_params['hidden_dims'], bias=model_params['bias'], output_type=model_params['output_type'])\n",
    "    nparam = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    all_model_df.loc[i, 'nparams'] = nparam\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    mean_ve, std_ve, min_ve, max_ve = train(model,rieml_data_seq['train'],parameters_seq['train'], rieml_data_seq['validate'],parameters_seq['validate'], modellevel=layers, model_name=model_params['model_name'])\n",
    "\n",
    "    t1 = time.time() - t0\n",
    "    hrs = t1//3600\n",
    "    minute = (t1-hrs*3600)//60\n",
    "    sec = (t1 - hrs*3600-minute*60)#//60\n",
    "    total_time=\"%02d:%02d:%02d\"%(hrs,minute,sec)\n",
    "    all_model_df.loc[i, 'time'] = total_time\n",
    "    all_model_df.loc[i, 'mean_ve'] = mean_ve\n",
    "    all_model_df.loc[i, 'std_ve'] = std_ve\n",
    "    all_model_df.loc[i, 'min_ve'] = min_ve\n",
    "    all_model_df.loc[i, 'max_ve'] = max_ve\n",
    "\n",
    "    #test losses\n",
    "    loss_test = plot.compute_losses_gru(model, rieml_data_seq['test'],parameters_seq['test'])\n",
    "    all_model_df.loc[i, 'mean_e_test'] = loss_test.mean()\n",
    "    all_model_df.loc[i, 'std_e_test'] = loss_test.std()\n",
    "    all_model_df.loc[i, 'min_e_test'] = loss_test.min()\n",
    "    all_model_df.loc[i, 'max_e_test'] = loss_test.max()\n",
    "\n",
    "#save file after all models are trained and tested\n",
    "#sort by mean validation error\n",
    "all_model_df = all_model_df.sort_values(by='max_e_test', ascending=True)\n",
    "all_model_df.to_csv('gridsearch_plots/level'+str(layers)+'_model_search_space.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>layers</th>\n",
       "      <th>bias</th>\n",
       "      <th>output_type</th>\n",
       "      <th>kernels</th>\n",
       "      <th>hidden_dims</th>\n",
       "      <th>nparams</th>\n",
       "      <th>time</th>\n",
       "      <th>mean_ve</th>\n",
       "      <th>std_ve</th>\n",
       "      <th>min_ve</th>\n",
       "      <th>max_ve</th>\n",
       "      <th>mean_e_test</th>\n",
       "      <th>std_e_test</th>\n",
       "      <th>min_e_test</th>\n",
       "      <th>max_e_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>model_23</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>1593231.0</td>\n",
       "      <td>00:14:15</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.027460</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.020778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>model_36</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1562559.0</td>\n",
       "      <td>00:12:27</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.021346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>model_26</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1558719.0</td>\n",
       "      <td>00:11:39</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.036274</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.002315</td>\n",
       "      <td>0.021561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>model_76</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1562508.0</td>\n",
       "      <td>00:12:38</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.022172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>model_44</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1705934.0</td>\n",
       "      <td>00:20:08</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.023610</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.022651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1558722.0</td>\n",
       "      <td>00:12:01</td>\n",
       "      <td>0.006538</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.029864</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.022901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>model_67</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1571148.0</td>\n",
       "      <td>00:12:36</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.038187</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.023126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>model_41</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1556750.0</td>\n",
       "      <td>00:11:48</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.025833</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.023561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>model_27</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1571247.0</td>\n",
       "      <td>00:12:36</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.023567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>model_31</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1560639.0</td>\n",
       "      <td>00:11:41</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.024856</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.002692</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.023687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>model_42</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1564238.0</td>\n",
       "      <td>00:12:47</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.023705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>model_28</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>1619343.0</td>\n",
       "      <td>00:14:56</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.023867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>model_45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>1555310.0</td>\n",
       "      <td>00:10:58</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.029694</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.024642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>model_79</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>2010060.0</td>\n",
       "      <td>00:28:42</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.029716</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.025110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1571250.0</td>\n",
       "      <td>00:13:17</td>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.025780</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.025143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>model_40</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>1554734.0</td>\n",
       "      <td>00:10:52</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.025270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>model_64</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1705932.0</td>\n",
       "      <td>00:18:08</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.022466</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.025288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>model_24</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1706319.0</td>\n",
       "      <td>00:18:09</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.025320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1706322.0</td>\n",
       "      <td>00:20:38</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.025397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>1593234.0</td>\n",
       "      <td>00:15:25</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.030197</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.025475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  layers   bias output_type kernels hidden_dims    nparams  \\\n",
       "23   model_23       1   True       final     [3]        [64]  1593231.0   \n",
       "36   model_36       1   True       final     [9]        [16]  1562559.0   \n",
       "26   model_26       1   True       final     [5]        [16]  1558719.0   \n",
       "76   model_76       1  False       final     [9]        [16]  1562508.0   \n",
       "44   model_44       1  False     reduced     [3]       [128]  1705934.0   \n",
       "6     model_6       1   True     reduced     [5]        [16]  1558722.0   \n",
       "67   model_67       1  False       final     [5]        [32]  1571148.0   \n",
       "41   model_41       1  False     reduced     [3]        [16]  1556750.0   \n",
       "27   model_27       1   True       final     [5]        [32]  1571247.0   \n",
       "31   model_31       1   True       final     [7]        [16]  1560639.0   \n",
       "42   model_42       1  False     reduced     [3]        [32]  1564238.0   \n",
       "28   model_28       1   True       final     [5]        [64]  1619343.0   \n",
       "45   model_45       1  False     reduced     [5]         [8]  1555310.0   \n",
       "79   model_79       1  False       final     [9]       [128]  2010060.0   \n",
       "7     model_7       1   True     reduced     [5]        [32]  1571250.0   \n",
       "40   model_40       1  False     reduced     [3]         [8]  1554734.0   \n",
       "64   model_64       1  False       final     [3]       [128]  1705932.0   \n",
       "24   model_24       1   True       final     [3]       [128]  1706319.0   \n",
       "4     model_4       1   True     reduced     [3]       [128]  1706322.0   \n",
       "3     model_3       1   True     reduced     [3]        [64]  1593234.0   \n",
       "\n",
       "        time   mean_ve    std_ve    min_ve    max_ve  mean_e_test  std_e_test  \\\n",
       "23  00:14:15  0.006388  0.005171  0.002197  0.027460     0.005296    0.002783   \n",
       "36  00:12:27  0.006519  0.004889  0.002010  0.023076     0.005346    0.002694   \n",
       "26  00:11:39  0.006656  0.006467  0.001901  0.036274     0.004879    0.002478   \n",
       "76  00:12:38  0.005696  0.004498  0.001822  0.023517     0.004916    0.002886   \n",
       "44  00:20:08  0.005410  0.004991  0.001495  0.023610     0.004216    0.002754   \n",
       "6   00:12:01  0.006538  0.005773  0.001749  0.029864     0.005457    0.002856   \n",
       "67  00:12:36  0.005984  0.006493  0.001598  0.038187     0.004772    0.002807   \n",
       "41  00:11:48  0.005897  0.005368  0.001909  0.025833     0.004666    0.002765   \n",
       "27  00:12:36  0.006465  0.005209  0.002260  0.026665     0.005150    0.002929   \n",
       "31  00:11:41  0.005761  0.004894  0.001634  0.024856     0.004806    0.002692   \n",
       "42  00:12:47  0.006090  0.005198  0.002179  0.025199     0.004815    0.002873   \n",
       "28  00:14:56  0.006199  0.005772  0.001833  0.029321     0.005050    0.002995   \n",
       "45  00:10:58  0.005848  0.005698  0.001753  0.029694     0.004672    0.002770   \n",
       "79  00:28:42  0.006832  0.005926  0.001941  0.029716     0.005432    0.003115   \n",
       "7   00:13:17  0.006971  0.006068  0.001664  0.025780     0.005574    0.003583   \n",
       "40  00:10:52  0.005950  0.005118  0.001766  0.023533     0.004860    0.002967   \n",
       "64  00:18:08  0.005875  0.004873  0.001928  0.022466     0.004898    0.003139   \n",
       "24  00:18:09  0.006370  0.005439  0.001905  0.024643     0.005174    0.002983   \n",
       "4   00:20:38  0.006255  0.005164  0.001875  0.026090     0.005192    0.002931   \n",
       "3   00:15:25  0.005746  0.005729  0.001490  0.030197     0.004475    0.002900   \n",
       "\n",
       "    min_e_test  max_e_test  \n",
       "23    0.002249    0.020778  \n",
       "36    0.002305    0.021346  \n",
       "26    0.002315    0.021561  \n",
       "76    0.001711    0.022172  \n",
       "44    0.001745    0.022651  \n",
       "6     0.002107    0.022901  \n",
       "67    0.001742    0.023126  \n",
       "41    0.001890    0.023561  \n",
       "27    0.001761    0.023567  \n",
       "31    0.002058    0.023687  \n",
       "42    0.001790    0.023705  \n",
       "28    0.002182    0.023867  \n",
       "45    0.001713    0.024642  \n",
       "79    0.002063    0.025110  \n",
       "7     0.001897    0.025143  \n",
       "40    0.001804    0.025270  \n",
       "64    0.002079    0.025288  \n",
       "24    0.002086    0.025320  \n",
       "4     0.001781    0.025397  \n",
       "3     0.001713    0.025475  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>layers</th>\n",
       "      <th>bias</th>\n",
       "      <th>output_type</th>\n",
       "      <th>kernels</th>\n",
       "      <th>hidden_dims</th>\n",
       "      <th>nparams</th>\n",
       "      <th>time</th>\n",
       "      <th>mean_ve</th>\n",
       "      <th>std_ve</th>\n",
       "      <th>min_ve</th>\n",
       "      <th>max_ve</th>\n",
       "      <th>mean_e_test</th>\n",
       "      <th>std_e_test</th>\n",
       "      <th>min_e_test</th>\n",
       "      <th>max_e_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>model_46</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1558670.0</td>\n",
       "      <td>00:11:57</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.001659</td>\n",
       "      <td>0.024880</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.003090</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.027493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>model_57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1584974.0</td>\n",
       "      <td>00:14:39</td>\n",
       "      <td>0.006160</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.025850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>model_19</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>2010450.0</td>\n",
       "      <td>00:27:30</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.027369</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.029889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>model_33</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>1645455.0</td>\n",
       "      <td>00:15:42</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.027630</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.030883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>model_76</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1562508.0</td>\n",
       "      <td>00:12:38</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.023517</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.022172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>model_45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>1555310.0</td>\n",
       "      <td>00:10:58</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.029694</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.024642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>1593234.0</td>\n",
       "      <td>00:15:25</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.030197</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.025475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>model_68</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>1619148.0</td>\n",
       "      <td>00:15:13</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.032674</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.029936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>model_67</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1571148.0</td>\n",
       "      <td>00:12:36</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.038187</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.023126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>model_44</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1705934.0</td>\n",
       "      <td>00:20:08</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.023610</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.022651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>model_27</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1571247.0</td>\n",
       "      <td>00:12:36</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>0.023567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>model_32</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>final</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1578159.0</td>\n",
       "      <td>00:12:50</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.029684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1706322.0</td>\n",
       "      <td>00:20:38</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.025397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>model_42</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1564238.0</td>\n",
       "      <td>00:12:47</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.023705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>model_47</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1571150.0</td>\n",
       "      <td>00:13:03</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.027016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>model_40</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>1554734.0</td>\n",
       "      <td>00:10:52</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.023533</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.025270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>model_18</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[64]</td>\n",
       "      <td>1671570.0</td>\n",
       "      <td>00:18:12</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.024179</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.026725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>model_61</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>final</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1556748.0</td>\n",
       "      <td>00:11:23</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>0.006245</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.032676</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.026966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>model_41</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1556750.0</td>\n",
       "      <td>00:11:48</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.025833</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.023561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>reduced</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[32]</td>\n",
       "      <td>1571250.0</td>\n",
       "      <td>00:13:17</td>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.025780</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.025143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  layers   bias output_type kernels hidden_dims    nparams  \\\n",
       "46   model_46       1  False     reduced     [5]        [16]  1558670.0   \n",
       "57   model_57       1  False     reduced     [9]        [32]  1584974.0   \n",
       "19   model_19       1   True     reduced     [9]       [128]  2010450.0   \n",
       "33   model_33       1   True       final     [7]        [64]  1645455.0   \n",
       "76   model_76       1  False       final     [9]        [16]  1562508.0   \n",
       "45   model_45       1  False     reduced     [5]         [8]  1555310.0   \n",
       "3     model_3       1   True     reduced     [3]        [64]  1593234.0   \n",
       "68   model_68       1  False       final     [5]        [64]  1619148.0   \n",
       "67   model_67       1  False       final     [5]        [32]  1571148.0   \n",
       "44   model_44       1  False     reduced     [3]       [128]  1705934.0   \n",
       "27   model_27       1   True       final     [5]        [32]  1571247.0   \n",
       "32   model_32       1   True       final     [7]        [32]  1578159.0   \n",
       "4     model_4       1   True     reduced     [3]       [128]  1706322.0   \n",
       "42   model_42       1  False     reduced     [3]        [32]  1564238.0   \n",
       "47   model_47       1  False     reduced     [5]        [32]  1571150.0   \n",
       "40   model_40       1  False     reduced     [3]         [8]  1554734.0   \n",
       "18   model_18       1   True     reduced     [9]        [64]  1671570.0   \n",
       "61   model_61       1  False       final     [3]        [16]  1556748.0   \n",
       "41   model_41       1  False     reduced     [3]        [16]  1556750.0   \n",
       "7     model_7       1   True     reduced     [5]        [32]  1571250.0   \n",
       "\n",
       "        time   mean_ve    std_ve    min_ve    max_ve  mean_e_test  std_e_test  \\\n",
       "46  00:11:57  0.005707  0.005006  0.001659  0.024880     0.004467    0.003090   \n",
       "57  00:14:39  0.006160  0.005857  0.001799  0.031032     0.004708    0.002974   \n",
       "19  00:27:30  0.006473  0.005161  0.002003  0.027369     0.005349    0.003442   \n",
       "33  00:15:42  0.006332  0.005419  0.001955  0.027630     0.005214    0.003405   \n",
       "76  00:12:38  0.005696  0.004498  0.001822  0.023517     0.004916    0.002886   \n",
       "45  00:10:58  0.005848  0.005698  0.001753  0.029694     0.004672    0.002770   \n",
       "3   00:15:25  0.005746  0.005729  0.001490  0.030197     0.004475    0.002900   \n",
       "68  00:15:13  0.006334  0.005408  0.001847  0.032674     0.005324    0.003427   \n",
       "67  00:12:36  0.005984  0.006493  0.001598  0.038187     0.004772    0.002807   \n",
       "44  00:20:08  0.005410  0.004991  0.001495  0.023610     0.004216    0.002754   \n",
       "27  00:12:36  0.006465  0.005209  0.002260  0.026665     0.005150    0.002929   \n",
       "32  00:12:50  0.006410  0.005165  0.001643  0.025268     0.005087    0.003202   \n",
       "4   00:20:38  0.006255  0.005164  0.001875  0.026090     0.005192    0.002931   \n",
       "42  00:12:47  0.006090  0.005198  0.002179  0.025199     0.004815    0.002873   \n",
       "47  00:13:03  0.005099  0.004487  0.001571  0.023380     0.004241    0.002952   \n",
       "40  00:10:52  0.005950  0.005118  0.001766  0.023533     0.004860    0.002967   \n",
       "18  00:18:12  0.006100  0.005125  0.001948  0.024179     0.004955    0.003021   \n",
       "61  00:11:23  0.006657  0.006245  0.002121  0.032676     0.005389    0.003433   \n",
       "41  00:11:48  0.005897  0.005368  0.001909  0.025833     0.004666    0.002765   \n",
       "7   00:13:17  0.006971  0.006068  0.001664  0.025780     0.005574    0.003583   \n",
       "\n",
       "    min_e_test  max_e_test  \n",
       "46    0.001509    0.027493  \n",
       "57    0.001619    0.025850  \n",
       "19    0.001671    0.029889  \n",
       "33    0.001689    0.030883  \n",
       "76    0.001711    0.022172  \n",
       "45    0.001713    0.024642  \n",
       "3     0.001713    0.025475  \n",
       "68    0.001735    0.029936  \n",
       "67    0.001742    0.023126  \n",
       "44    0.001745    0.022651  \n",
       "27    0.001761    0.023567  \n",
       "32    0.001778    0.029684  \n",
       "4     0.001781    0.025397  \n",
       "42    0.001790    0.023705  \n",
       "47    0.001791    0.027016  \n",
       "40    0.001804    0.025270  \n",
       "18    0.001818    0.026725  \n",
       "61    0.001841    0.026966  \n",
       "41    0.001890    0.023561  \n",
       "7     0.001897    0.025143  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_df = all_model_df.sort_values(by='min_e_test', ascending=True)\n",
    "all_model_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain and save the best n models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses\n",
      "plot\n",
      "./plots/rieML_test959_test_best_0000\n",
      "./plots/rieML_test959_test_best_0001\n",
      "./plots/rieML_test959_test_best_0002\n",
      "./plots/rieML_test959_test_best_0003\n",
      "./plots/rieML_test959_test_best_0004\n",
      "./plots/rieML_test959_test_worst_0000\n",
      "./plots/rieML_test959_test_worst_0001\n",
      "./plots/rieML_test959_test_worst_0002\n",
      "./plots/rieML_test959_test_worst_0003\n",
      "./plots/rieML_test959_test_worst_0004\n",
      "./plots/rieML_test959_train_best_0000\n",
      "./plots/rieML_test959_train_best_0001\n",
      "./plots/rieML_test959_train_best_0002\n",
      "./plots/rieML_test959_train_best_0003\n",
      "./plots/rieML_test959_train_best_0004\n",
      "./plots/rieML_test959_train_worst_0000\n",
      "./plots/rieML_test959_train_worst_0001\n",
      "./plots/rieML_test959_train_worst_0002\n",
      "./plots/rieML_test959_train_worst_0003\n",
      "./plots/rieML_test959_train_worst_0004\n",
      "./plots/rieML_test0959_avalidate_0000\n",
      "./plots/rieML_test0959_avalidate_0001\n",
      "./plots/rieML_test0959_avalidate_0002\n",
      "./plots/rieML_test0959_avalidate_0003\n",
      "./plots/rieML_test0959_avalidate_0004\n",
      "./plots/rieML_test0959_avalidate_0005\n",
      "./plots/rieML_test0959_avalidate_0006\n",
      "./plots/rieML_test0959_avalidate_0007\n",
      "./plots/rieML_test0959_avalidate_0008\n",
      "./plots/rieML_test0959_avalidate_0009\n",
      "./plots/rieML_test0959_avalidate_0010\n",
      "./plots/rieML_test0959_avalidate_0011\n",
      "./plots/rieML_test0959_avalidate_0012\n",
      "./plots/rieML_test0959_avalidate_0013\n",
      "./plots/rieML_test0959_avalidate_0014\n",
      "./plots/rieML_test0959_avalidate_0015\n",
      "./plots/rieML_test0959_avalidate_0016\n",
      "./plots/rieML_test0959_avalidate_0017\n",
      "./plots/rieML_test0959_avalidate_0018\n",
      "./plots/rieML_test0959_avalidate_0019\n",
      "./plots/rieML_test0959_avalidate_0020\n",
      "./plots/rieML_test0959_avalidate_0021\n",
      "./plots/rieML_test0959_avalidate_0022\n",
      "./plots/rieML_test0959_avalidate_0023\n",
      "./plots/rieML_test0959_avalidate_0024\n",
      "./plots/rieML_test0959_avalidate_0025\n",
      "./plots/rieML_test0959_avalidate_0026\n",
      "./plots/rieML_test0959_avalidate_0027\n",
      "./plots/rieML_test0959_avalidate_0028\n",
      "./plots/rieML_test0959_avalidate_0029\n",
      "./plots/rieML_test0959_avalidate_0030\n",
      "./plots/rieML_test0959_avalidate_0031\n",
      "./plots/rieML_test0959_avalidate_0032\n",
      "./plots/rieML_test0959_avalidate_0033\n",
      "./plots/rieML_test0959_avalidate_0034\n",
      "./plots/rieML_test0959_avalidate_0035\n",
      "./plots/rieML_test0959_avalidate_0036\n",
      "./plots/rieML_test0959_avalidate_0037\n",
      "./plots/rieML_test0959_avalidate_0038\n",
      "./plots/rieML_test0959_avalidate_0039\n",
      "./plots/rieML_test0959_avalidate_0040\n",
      "./plots/rieML_test0959_avalidate_0041\n",
      "./plots/rieML_test0959_avalidate_0042\n",
      "./plots/rieML_test0959_avalidate_0043\n",
      "./plots/rieML_test0959_avalidate_0044\n",
      "./plots/rieML_test0959_avalidate_0045\n",
      "./plots/rieML_test0959_avalidate_0046\n",
      "./plots/rieML_test0959_avalidate_0047\n",
      "./plots/rieML_test0959_avalidate_0048\n",
      "./plots/rieML_test0959_avalidate_0049\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_model = 1\n",
    "skip_train_plot = 2  #skip every nth element in array for high parameter models, 1 for low parameter model that don't cause kernel crash\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(\"models/test%d.pth\"%idd))\n",
    "if 1:\n",
    "    print('losses')\n",
    "    loss_train = torch.from_numpy(plot.compute_losses_gru(model, rieml_data_seq['train'][::skip_train_plot],parameters_seq['train'][::skip_train_plot]))\n",
    "    loss_test = torch.from_numpy(plot.compute_losses_gru(model, rieml_data_seq['test'],parameters_seq['test']))\n",
    "    loss_validate = torch.from_numpy(plot.compute_losses_gru(model, rieml_data_seq['validate'],parameters_seq['validate']))\n",
    "    args_train = torch.argsort(loss_train)\n",
    "    args_test = torch.argsort(loss_test)\n",
    "    #args_validate = torch.argsort(loss_validate)\n",
    "if 1:\n",
    "    print('plot')\n",
    "    plot.plot_hist(loss_train,loss_test,loss_validate,idd)\n",
    "\n",
    "    zzz=plot.test_plot_gru(rieml_data_seq['test'][args_test[:5]], parameters_seq['test'][args_test[:5]], model, fname=\"test%d_test_best\"%testnum)\n",
    "    zzz=plot.test_plot_gru(rieml_data_seq['test'][args_test[-5:]], parameters_seq['test'][args_test[-5:]], model, fname=\"test%d_test_worst\"%testnum)\n",
    "    zzz=plot.test_plot_gru(rieml_data_seq['train'][::skip_train_plot][args_train[:5]], parameters_seq['train'][::skip_train_plot][args_train[:5]], model, fname=\"test%d_train_best\"%testnum)\n",
    "    zzz=plot.test_plot_gru(rieml_data_seq['train'][::skip_train_plot][args_train[-5:]], parameters_seq['train'][::skip_train_plot][args_train[-5:]], model, fname=\"test%d_train_worst\"%testnum)\n",
    "    zzz=plot.test_plot_gru(rieml_data_seq['validate'], parameters_seq['validate'], model, fname=\"test%04d_avalidate\"%testnum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nikhil_20241011",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
