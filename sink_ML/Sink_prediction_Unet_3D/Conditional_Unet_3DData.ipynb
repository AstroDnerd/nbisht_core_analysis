{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Unet DATA Prediction\n",
    "> Created May 2025 <br>\n",
    "> Nikhil Bisht<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cpu \n"
     ]
    }
   ],
   "source": [
    "# standard system modules\n",
    "import os, sys\n",
    "import h5py \n",
    "import argparse\n",
    "# standard module for tabular data\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# standard module for array manipulation\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "\n",
    "# standard statistical module\n",
    "import scipy.stats as st\n",
    "from scipy import linalg\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "# standard module for high-quality plots\n",
    "from PIL import Image\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "mp.rcParams.update(mp.rcParamsDefault)\n",
    "%matplotlib inline\n",
    "\n",
    "# to plot pixelized images\n",
    "import imageio.v3 as im\n",
    "\n",
    "# standard research-level machine learning toolkit from Meta (FKA: FaceBook)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import tables\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set a seed to ensure reproducibility\n",
    "seed = 128\n",
    "rnd  = np.random.RandomState(seed)\n",
    "\n",
    "DATAFILE  = '/data/cb1/nbisht/anvil_scratch/projects/128/B2/datasets/nb101_ML_dataset_AllData_AutoEnc.h5'\n",
    "IMAGEINPUT = '/data/cb1/nbisht/anvil_scratch/projects/128/B2/datasets/Unet/Images_Input_3D/'\n",
    "IMAGEOUTPUT = '/data/cb1/nbisht/anvil_scratch/projects/128/B2/datasets/Unet/Images_Output_3D/'\n",
    "CORESET  = '/data/cb1/nbisht/anvil_scratch/projects/128/B2/datasets/nb101_all_frames.h5'\n",
    "DENSITYCUBES = '/data/cb1/nbisht/anvil_scratch/projects/128/B2/datasets/nb101_TimeseriesCubes_Density.npy'\n",
    "MODELFILE = 'nnmodel.dict'\n",
    "\n",
    "IMAGESIZE = 128\n",
    "\n",
    "\n",
    "FRAMES = np.arange(0,90, 1)\n",
    "FRAME_DIFF = 30\n",
    "\n",
    "#DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "print(f'Available device: {str(DEVICE):4s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "def plot_images(images):\n",
    "    plt.figure(figsize=(32, 32))\n",
    "    plt.imshow(torch.cat([\n",
    "        torch.cat([i for i in images.cpu()], dim=-1),\n",
    "    ], dim=-2).permute(1, 2, 0).cpu())\n",
    "    plt.show()\n",
    "\n",
    "def get_data(args, input_arr, labels):\n",
    "    dataset = TensorDataset(input_arr, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def img_transform(np_arr):\n",
    "    return np.log10(np_arr)\n",
    "\n",
    "def img_inverse_transform(np_arr):\n",
    "    return np.power(10,np_arr)\n",
    "\n",
    "def plot_img_raw(Initial_fname, Final_fname, save_filename='xy_data.png', dont_show = False):\n",
    "    i_file = open(Initial_fname, 'r')\n",
    "    infile = json.load(i_file)\n",
    "    o_file = open(Final_fname, 'r')\n",
    "    outfile = json.load(o_file)\n",
    "\n",
    "    x1 = np.array(infile['img'])\n",
    "    x1_label = infile['label']\n",
    "    x2 = np.array(outfile['img'])\n",
    "    x2_label = outfile['label']\n",
    "    i_file.close()\n",
    "    o_file.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    proj_arr = ['xy', 'yz', 'zx']\n",
    "    for i in range(0,3):\n",
    "        ax  = fig.add_subplot(2, 3, 1+i)\n",
    "        c = ax.pcolormesh(np.mean(x1, axis=i).T)\n",
    "        fig.colorbar(c, ax=ax)\n",
    "        ax.set_title(proj_arr[i]+' proj '+str(x1_label[0])+'_'+str(x1_label[1])+'_'+str(x1_label[2]))\n",
    "        ax.grid('both')\n",
    "\n",
    "    for i in range(0,3):\n",
    "        ax2  = fig.add_subplot(2, 3, 4+i)\n",
    "        c = ax2.pcolormesh(np.mean(x2, axis=i).T)\n",
    "        fig.colorbar(c, ax=ax2)\n",
    "        ax2.set_title(proj_arr[i]+' proj '+str(x2_label[0])+'_'+str(x2_label[1])+'_'+str(x2_label[2]))\n",
    "        ax2.grid('both')\n",
    "\n",
    "    if save_filename:\n",
    "        plt.savefig(save_filename)\n",
    "    \n",
    "    if dont_show==False:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def data_augmentation_periodic(images_dictionary):\n",
    "    new_imgs_dictionary = {}\n",
    "    new_num = 0\n",
    "    for num in images_dictionary.keys():\n",
    "        initial_img = images_dictionary[str(num)]['initial_img']\n",
    "        final_img = images_dictionary[str(num)]['final_img']\n",
    "        img_frame = images_dictionary[str(num)]['label'][0]\n",
    "        img_projection = images_dictionary[str(num)]['label'][1]\n",
    "\n",
    "        #setup periodic wrap. shift to the right in steps of 64/4 = 16 pixels\n",
    "        shift1_i, shift1_f = np.zeros(initial_img.shape), np.zeros(final_img.shape)\n",
    "        shift2_i, shift2_f = np.zeros(initial_img.shape), np.zeros(final_img.shape)\n",
    "        shift3_i, shift3_f = np.zeros(initial_img.shape), np.zeros(final_img.shape)\n",
    "        \n",
    "        shift1_i[:48,:], shift1_f[:48,:] = initial_img[16:,:], final_img[16:,:]\n",
    "        shift1_i[48:,:], shift1_f[48:,:] = initial_img[0:16,:], final_img[0:16,:]\n",
    "\n",
    "        shift2_i[:32,:], shift2_f[:32,:] = initial_img[32:,:], final_img[32:,:]\n",
    "        shift2_i[32:,:], shift2_f[32:,:] = initial_img[0:32,:], final_img[0:32,:]\n",
    "\n",
    "        shift3_i[:16,:], shift3_f[:16,:] = initial_img[48:,:], final_img[48:,:]\n",
    "        shift3_i[16:,:], shift3_f[16:,:] = initial_img[0:48,:], final_img[0:48,:]\n",
    "\n",
    "        new_imgs_dictionary[str(new_num)] = {'initial_img':initial_img, 'final_img': final_img, 'label': (img_frame,img_projection,0)}\n",
    "        new_num+=1\n",
    "        new_imgs_dictionary[str(new_num)] = {'initial_img':shift1_i,'final_img': shift1_f,'label': (img_frame,img_projection,1)}\n",
    "        new_num+=1\n",
    "        new_imgs_dictionary[str(new_num)] = {'initial_img':shift2_i,'final_img': shift2_f,'label': (img_frame,img_projection,2)}\n",
    "        new_num+=1\n",
    "        new_imgs_dictionary[str(new_num)] = {'initial_img':shift3_i,'final_img': shift3_f,'label': (img_frame,img_projection,3)}\n",
    "        new_num+=1\n",
    "    \n",
    "    return new_imgs_dictionary\n",
    "\n",
    "def data_augmentation_rotate(images_dictionary):\n",
    "    from scipy import ndimage\n",
    "    rotated_imgs_dictionary = {}\n",
    "    new_num = 0\n",
    "    for num in range(len(images_dictionary.keys())):\n",
    "        initial_img = images_dictionary[str(num)]['initial_img']\n",
    "        final_img = images_dictionary[str(num)]['final_img']\n",
    "        img_frame = images_dictionary[str(num)]['label'][0]\n",
    "        img_wrap = images_dictionary[str(num)]['label'][2]\n",
    "        #setup rotation pairs: 4 rotations about y axis (0,2) and 2 rotations about x axis (1,2)\n",
    "        rotation_in_degrees = [  0,     90,   180,   270,   90,     270]\n",
    "        rotation_axes       = [(0,2), (0,2), (0,2), (0,2), (1,2), (1,2)]\n",
    "        projection_label_name  = [ 'xy',    'yz',  'yx',   'zy',   'zx',   'xz']\n",
    "        for rot_num in range(len(rotation_in_degrees)):\n",
    "            rotated_initial_img = ndimage.rotate(initial_img, rotation_in_degrees[rot_num], axes=rotation_axes[rot_num])\n",
    "            rotated_final_img = ndimage.rotate(final_img, rotation_in_degrees[rot_num], axes=rotation_axes[rot_num])\n",
    "            rotated_imgs_dictionary[str(new_num)] = {'initial_img':rotated_initial_img,'final_img': rotated_final_img,'label': (img_frame,projection_label_name[rot_num],img_wrap)}\n",
    "            new_num+=1\n",
    "\n",
    "    return rotated_imgs_dictionary\n",
    "\n",
    "def delete_folder_contents(folder):\n",
    "    import shutil\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def store_imgs(img_dict, input_dir = IMAGEINPUT, output_dir = IMAGEOUTPUT, rewrite = 1):\n",
    "    if rewrite==1:\n",
    "        num = 0\n",
    "        import shutil\n",
    "        for folder in [input_dir, output_dir]:\n",
    "            delete_folder_contents(folder)\n",
    "    else:\n",
    "        num = len(os.listdir(input_dir))\n",
    "    for img_num in img_dict.keys():\n",
    "        img_data = img_dict[img_num]\n",
    "        input_fname = input_dir+\"img_\"+str(num).zfill(4)+\".json\"\n",
    "        output_fname = output_dir+\"img_\"+str(num).zfill(4)+\".json\"\n",
    "        num+=1\n",
    "        if rewrite == 1:\n",
    "            infile = open(input_fname, 'w')\n",
    "            outfile = open(output_fname, 'w')\n",
    "        if rewrite == 0 and os.path.isfile(input_fname):\n",
    "            print(\"File exists!\")\n",
    "            return False\n",
    "        initial_img = {'img': img_data['initial_img'].tolist(), 'label': img_data['label']}\n",
    "        final_img = {'img': img_data['final_img'].tolist(), 'label': img_data['label']}\n",
    "        json.dump(initial_img, infile, cls=NpEncoder)\n",
    "        json.dump(final_img, outfile, cls=NpEncoder)\n",
    "        if rewrite == 1:\n",
    "            infile.close()\n",
    "            outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 128, 128, 128)\n",
      "torch.Size([121, 1, 64, 64, 64])\n",
      "(121, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "#get data and prepare sample\n",
    "#3D density Timeseries_Cube\n",
    "infile = open(DENSITYCUBES, 'rb')\n",
    "TSCube_density = np.load(infile)\n",
    "time_array = np.load(infile)\n",
    "infile.close()\n",
    "dsample = nn.AvgPool3d(2)\n",
    "print(TSCube_density.shape)\n",
    "TSCube_density = dsample(torch.from_numpy(TSCube_density).unsqueeze(1))\n",
    "print(TSCube_density.shape)\n",
    "TSCube_density = TSCube_density.squeeze(1).numpy()\n",
    "print(TSCube_density.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dictionary = {}\n",
    "num = len(images_dictionary.keys())\n",
    "for frame in FRAMES:\n",
    "    H_initial = img_transform(TSCube_density[frame])\n",
    "    H_final = img_transform(TSCube_density[frame+FRAME_DIFF])\n",
    "    images_dictionary[str(num)] = {'initial_img':H_initial,'final_img': H_final,'label': (frame,'xy',0)}\n",
    "    num+=1\n",
    "\n",
    "images_dictionary = data_augmentation_rotate(images_dictionary)\n",
    "images_dictionary = data_augmentation_periodic(images_dictionary)\n",
    "\n",
    "store_imgs(images_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the images\n",
    "delete_folder_contents('./3D_img_plots/')\n",
    "for num in range(len(images_dictionary.keys())):\n",
    "    img_num = str(num).zfill(4)\n",
    "    plot_img_raw(IMAGEINPUT+\"img_\"+img_num+\".json\", IMAGEOUTPUT+\"img_\"+img_num+\".json\", save_filename='./3D_img_plots/img'+img_num+'.png', dont_show = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nikhil_20241011",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
